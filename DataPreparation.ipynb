{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUQ74hQuRd79"
   },
   "source": [
    "This is like a utils module for my project, including useful functions, mainly for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1092,
     "status": "ok",
     "timestamp": 1607683592469,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "PIGaHWxJHi5P",
    "outputId": "c7919c9d-4c33-4dec-e63b-27bc5e9e7cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
      "[Errno 2] No such file or directory: 'gdrive/My Drive/Internship/Project'\n",
      "/content/gdrive/My Drive/Internship/Project\n"
     ]
    }
   ],
   "source": [
    "#  Mount google drive\n",
    "if __name__ == '__main__' and '__file__' not in globals():\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive/')\n",
    "  %cd gdrive/'My Drive'/Internship/Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7032,
     "status": "ok",
     "timestamp": 1607683598432,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "x1sN-iynIOTs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from pickle import dump, load\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from tensorflow.keras.models import Model, load_model, model_from_json\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "from scipy import fftpack\n",
    "# import scipy.fftpack._fftpack as sff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7827,
     "status": "ok",
     "timestamp": 1607683599236,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "VMZF6uX8IUoJ"
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 12239,
     "status": "ok",
     "timestamp": 1607683603492,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "t0A_C2rVIVXP"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "These functions are based on the impressions that there were many leading and trailing zeros in the recordings because of\n",
    "recording errors. In the end, they were useful to remove the beginning of the recordings for which the quality labels were all zero \n",
    "because they haven't started recording with the invasive technique yet.\n",
    "'''\n",
    "\n",
    "\n",
    "# It counts how many zeros exist in an array before the first one\n",
    "cpdef int c_count_leading_zeros(cnp.ndarray a, thr=1e-6):\n",
    "    cdef int elements = a.size\n",
    "    cdef int i = 0\n",
    "    cdef int count = 0\n",
    "    while i < elements:\n",
    "        if np.abs(a[i]) < thr:\n",
    "            count += 1\n",
    "        else:\n",
    "            return count\n",
    "        i += 1\n",
    "    return count\n",
    "\n",
    "# it counts how many consecutive zeros exist in the end of an array\n",
    "cpdef int c_count_trailing_zeros(cnp.ndarray a):\n",
    "    return c_count_leading_zeros(np.flip(a))\n",
    "\n",
    "# It removes leading and trailing zeros from an array\n",
    "cpdef cnp.ndarray c_trim_zeros_NEMO(cnp.ndarray arr):\n",
    "    # minimum number of leading zeros\n",
    "    max_lead = -np.inf\n",
    "    max_trail = -np.inf\n",
    "\n",
    "    cdef int i\n",
    "    for i in range(arr.shape[0]):\n",
    "        lead = c_count_leading_zeros(arr[i])\n",
    "        trail = c_count_trailing_zeros(arr[i])\n",
    "\n",
    "        if lead > max_lead:\n",
    "            max_lead = lead\n",
    "        if trail > max_trail:\n",
    "            max_trail = trail\n",
    "            \n",
    "    if max_lead == -np.inf:\n",
    "        start = 0\n",
    "    else:\n",
    "        start = max_lead\n",
    "        \n",
    "    if max_trail == -np.inf:\n",
    "        end = arr.shape[1]\n",
    "    else:\n",
    "        end = arr.shape[1] - max_trail\n",
    "\n",
    "    return arr[:,start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 12558,
     "status": "ok",
     "timestamp": 1607683603987,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "6xyGhsLz790Z"
   },
   "outputs": [],
   "source": [
    "# Python wrapper of the previous cython functions\n",
    "def count_leading_zeros(a):\n",
    "  return(c_count_leading_zeros(a))\n",
    "\n",
    "def count_trailing_zeros(a):\n",
    "  return c_count_trailing_zeros(a)\n",
    "\n",
    "def trim_zeros_NEMO(a):\n",
    "  return c_trim_zeros_NEMO(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 12682,
     "status": "ok",
     "timestamp": 1607683604121,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "1DVI510GIZe2"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from __main__ import trim_zeros_NEMO\n",
    "\n",
    "'''\n",
    "Create dataset from the NEMO dataset\n",
    "path: path to the train and test directories\n",
    "snippet_len: length of a snippet (number of timesteps in an LSTM network)\n",
    "RETURN: array in appropriate format to be fed to the NN\n",
    "''' \n",
    "cpdef cnp.ndarray create_dataset(path = r'Data/fetal_quality_assessment/train', snippet_len=125):\n",
    "\n",
    "  cdef cnp.ndarray signal\n",
    "  cdef int leftovers\n",
    "  cdef int i\n",
    "  cdef int iters\n",
    "  cdef cnp.ndarray dataset = np.zeros(shape=(0,snippet_len, 4))\n",
    "  cdef cnp.ndarray temp_dataset\n",
    "\n",
    "  filenames = os.listdir(path)\n",
    "\n",
    "  for name in tqdm(filenames):\n",
    "\n",
    "    file_signal = h5py.File(path+'/'+name, 'r')\n",
    "    signal = file_signal['data'][()]\n",
    "    file_signal.close()\n",
    "\n",
    "    # trim leading and trailing zeros\n",
    "    signal = trim_zeros_NEMO(signal)\n",
    "\n",
    "    # make it an integer multiple of snippet_len\n",
    "    leftovers = signal.shape[1]%snippet_len\n",
    "    if leftovers != 0:\n",
    "      signal = signal[:,:-leftovers]\n",
    "\n",
    "    temp_dataset = np.zeros((signal.shape[1]//snippet_len-1, snippet_len, signal.shape[0]))\n",
    "\n",
    "    iters = signal.shape[1]//snippet_len\n",
    "    for i in range(0, iters):\n",
    "      temp_dataset[i] = signal[:,i*snippet_len:(i+1)*snippet_len].T\n",
    "    \n",
    "    dataset = np.vstack((dataset, temp_dataset))\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 13017,
     "status": "ok",
     "timestamp": 1607683604468,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "r8kU54cQIbUo"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from __main__ import trim_zeros_NEMO\n",
    "\n",
    "'''\n",
    "Create dataset from the a single NEMO file\n",
    "name: filename including path\n",
    "snippet_len: length of a snippet (number of timesteps in an LSTM network)\n",
    "RETURN: array in appropriate format to be fed to the NN\n",
    "''' \n",
    "cpdef create_dataset_from_file(name, snippet_len=125, sliding_window=False, trim_zeros=True, return_leftovers=False):\n",
    "# def create_dataset_from_file(name, snippet_len=125, sliding_window=False, trim_zeros=True, return_leftovers=False):\n",
    "\n",
    "  cdef cnp.ndarray signal\n",
    "  cdef int leftovers\n",
    "  cdef int i\n",
    "  cdef int iters\n",
    "  cdef cnp.ndarray dataset = np.zeros(shape=(0,snippet_len, 4))\n",
    "  cdef cnp.ndarray temp_dataset\n",
    "\n",
    "  file_signal = h5py.File(name, 'r')\n",
    "  signal = file_signal['data'][()]\n",
    "  file_signal.close()\n",
    "\n",
    "  # trim leading and trailing zeros\n",
    "  if trim_zeros:\n",
    "    signal = trim_zeros_NEMO(signal)\n",
    "\n",
    "  # make it an integer multiple of snippet_len\n",
    "  leftovers = signal.shape[1]%snippet_len\n",
    "  if leftovers != 0:\n",
    "    signal = signal[:,:-leftovers]\n",
    "\n",
    "  if not sliding_window or snippet_len==125:\n",
    "\n",
    "    dataset = np.zeros((signal.shape[1]//snippet_len, snippet_len, signal.shape[0]))\n",
    "\n",
    "    iters = signal.shape[1]//snippet_len-1\n",
    "    for i in range(0, iters):\n",
    "      dataset[i] = signal[:,i*snippet_len:(i+1)*snippet_len].T\n",
    "    \n",
    "  \n",
    "  else:\n",
    "\n",
    "    dataset = np.zeros(((signal.shape[1]-snippet_len)//125, snippet_len, signal.shape[0]))\n",
    "\n",
    "    i = 0\n",
    "    while i*125+snippet_len < signal.shape[1]:\n",
    "      s = signal[:,i*125:i*125+snippet_len].T\n",
    "      dataset[i,:,:] = s\n",
    "      i += 1\n",
    "\n",
    "  if return_leftovers:    \n",
    "    return dataset, leftovers\n",
    "  else:\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 13008,
     "status": "ok",
     "timestamp": 1607683604469,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "XtQGEGFDdBXd"
   },
   "outputs": [],
   "source": [
    "# remove the nan values from the quality arrays, replace them with low quality\n",
    "def remove_nan(quality):\n",
    "  quality[np.where(np.isnan(quality) == True)] = 0\n",
    "  return quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 12997,
     "status": "ok",
     "timestamp": 1607683604470,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "PQLTBUcTJ0db"
   },
   "outputs": [],
   "source": [
    "# remove the inf values from the recording arrays, replace them with the non infinite maximum/minimum\n",
    "def remove_inf(signal):\n",
    "\n",
    "  no_inf = np.copy(signal)\n",
    "  no_inf[np.where(np.isinf(signal) == True)] = 0\n",
    "  maximum = np.max(no_inf)\n",
    "  minimum = np.min(no_inf)\n",
    "\n",
    "  signal[np.where(signal == np.inf)] = maximum\n",
    "  signal[np.where(signal == -np.inf)] = minimum\n",
    "\n",
    "  return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 12991,
     "status": "ok",
     "timestamp": 1607683604473,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "tNVwsQ0TJCpI"
   },
   "outputs": [],
   "source": [
    "# It creates a Robust scaler from the data\n",
    "def create_scaler(data):\n",
    "  scaler = RobustScaler()\n",
    "  scaler.fit(data.reshape(-1,4))\n",
    "  return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 12982,
     "status": "ok",
     "timestamp": 1607683604475,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "7rF8sH0TJEbt"
   },
   "outputs": [],
   "source": [
    "# It scales the data using the given scaler in the format appropriate for training our networks\n",
    "def scale_data(data, scaler, snippet_len=125):\n",
    "  return scaler.transform(data.reshape(-1,4)).reshape(-1, snippet_len, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 14269,
     "status": "ok",
     "timestamp": 1607683605773,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "AU9qsAqEKukH"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "'''\n",
    "(Not used in the end because of the spread of low quality recordings)\n",
    "This function will turn the dataset in a clean version where the recordings do not contain many low quality data points.\n",
    "Filenames include paths. \n",
    "max_bad_points: the maximum allowed number of \"bad\" datapoints in a recording\n",
    "min_duration: the minimum duration of a recording in seconds,\n",
    "data_filename: path+name of the data file \n",
    "quality_filename: path+name of the data file \n",
    "snippet_len: how many datapoints correspond to one quality point\n",
    "RETURN: a list of recordings (arrays)\n",
    "'''\n",
    "cpdef list create_clean_train_set(int max_bad_points, int min_duration, str data_filename, str quality_filename, int snippet_len=125):\n",
    "\n",
    "  cdef int bad_counter = 0\n",
    "  cdef int starting_index = 0\n",
    "  cdef int ending_index = 0\n",
    "  cdef int i\n",
    "  cdef int total_counter = 0\n",
    "  cdef list signals = []\n",
    "\n",
    "  file_signal = h5py.File(quality_filename, 'r')\n",
    "  cdef cnp.ndarray quality = file_signal['data'][()][0]\n",
    "  file_signal.close()\n",
    "\n",
    "  quality[np.where(np.isnan(quality) == True)] = 0\n",
    "\n",
    "  file_signal = h5py.File(data_filename, 'r')\n",
    "  cdef cnp.ndarray data = file_signal['data'][()]\n",
    "  file_signal.close()\n",
    "\n",
    "  for i in range(len(quality)):\n",
    "    \n",
    "    total_counter += 1\n",
    "\n",
    "    if quality[i] == 0:\n",
    "      bad_counter += 1\n",
    "\n",
    "    if bad_counter <= max_bad_points and total_counter/4 >= min_duration:\n",
    "\n",
    "      ending_index = i\n",
    "      signals.append(data[:, starting_index*snippet_len : (ending_index+1)*snippet_len])\n",
    "\n",
    "      starting_index = i+1\n",
    "      total_counter = 0\n",
    "      bad_counter = 0\n",
    "        \n",
    "  return signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 14274,
     "status": "ok",
     "timestamp": 1607683605786,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "YJeHH0rG0mK7"
   },
   "outputs": [],
   "source": [
    "# Not used in the end\n",
    "def clean_data(max_bad_points, min_duration, path = r'Data/fetal_quality_assessment'):\n",
    "  filenames_with_ending = os.listdir(path+'/train')\n",
    "  filenames = []\n",
    "  for n in filenames_with_ending:\n",
    "    filenames.append(n[:-12])\n",
    "\n",
    "  for name in tqdm(filenames):\n",
    "    signals = create_clean_train_set(max_bad_points, min_duration, path+'/train/'+name+'.fetalSignal', path+'/quality_files/'+name+'.quality')\n",
    "\n",
    "    for i in range(len(signals)):\n",
    "\n",
    "      recording = signals[i]\n",
    "\n",
    "      hf = h5py.File(r'Data/clean_data/{}.h5'.format(name+'__'+str(i)), 'w')\n",
    "      hf.create_dataset('data', data=recording)\n",
    "      hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 14265,
     "status": "ok",
     "timestamp": 1607683605787,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "qYUTdCZG-l3G"
   },
   "outputs": [],
   "source": [
    "# clean_data(max_bad_points=50, min_duration=30, path=r'Data/fetal_quality_assessment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 14253,
     "status": "ok",
     "timestamp": 1607683605789,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "M3nTwywFv2VM"
   },
   "outputs": [],
   "source": [
    "# serialize Keras model to JSON and save the weights in one signle function\n",
    "def save_model(model, name):\n",
    "  model_json = model.to_json()\n",
    "  with open(name+\".json\", \"w\") as json_file:\n",
    "      json_file.write(model_json)\n",
    "  # serialize weights to HDF5\n",
    "  model.save_weights(name+\".h5\")\n",
    "  print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 14246,
     "status": "ok",
     "timestamp": 1607683605790,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "szeoGg4OwIWY"
   },
   "outputs": [],
   "source": [
    "# Load model saved with the previous function\n",
    "def load_model(filename):\n",
    "  json_file = open(filename+'.json', 'r')\n",
    "  loaded_model_json = json_file.read()\n",
    "  json_file.close()\n",
    "  loaded_model = model_from_json(loaded_model_json)\n",
    "  # load weights into new model\n",
    "  loaded_model.load_weights(filename+\".h5\")\n",
    "  print(\"Loaded model from disk\")\n",
    "  return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 14238,
     "status": "ok",
     "timestamp": 1607683605791,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "ZdlnydxlNYXA"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function generates files each containing the data for a batch. The batches contain recordings of length snippet_len\n",
    "and each sample is moved by 125 datapoints (0.25 seconds). Therefore, the samples have a lot of overlap. The idea was to do the preprocessing\n",
    "beforehand and then load the data from storage (because they couldn't fit in the RAM). In the end, it turned out that loading the I/O operations\n",
    "take longer than the preprocessing. I didn't use that since I sticked to samples of snippet_len=125\n",
    "'''\n",
    "def create_batches(data_path, save_path, scaler, batch_size=32, snippet_len=125, clean=True, channels=4):\n",
    "\n",
    "  filenames = os.listdir(data_path)\n",
    "\n",
    "  # initialization\n",
    "  batch = np.zeros((batch_size, snippet_len, channels))\n",
    "  batch_index = 0\n",
    "  batch_num = 0\n",
    "\n",
    "  for name in tqdm(filenames):\n",
    "    ##### Accessing data from files and preprocession ####\n",
    "\n",
    "    file_name = data_path + '/' + name\n",
    "    file_signal = h5py.File(file_name, 'r')\n",
    "    signal = file_signal['data'][()]\n",
    "    file_signal.close()\n",
    "\n",
    "    file_signal = self.scaler.transform(file_signal.T).T\n",
    "\n",
    "    quality_name = 'Data/fetal_quality_assessment/quality_files/' + name[:-12] + '.quality'\n",
    "    file_signal = h5py.File(quality_name, 'r')\n",
    "    signal_quality = file_signal['data'][()]\n",
    "    file_signal.close()\n",
    "    signal_quality = remove_nan(signal_quality)\n",
    "    signal_quality = signal_quality.flatten()\n",
    "\n",
    "    # make it an integer multiple of snippet_len\n",
    "    leftovers = signal.shape[1]%snippet_len\n",
    "    if leftovers != 0:\n",
    "      signal = signal[:,:-leftovers]\n",
    "      signal_quality = signal_quality[snippet_len//125-1:-leftovers//125]\n",
    "    else:\n",
    "      signal_quality = signal_quality[snippet_len//125-1:]\n",
    "\n",
    "    #### Creating batch files ######\n",
    "\n",
    "    signal_index = 0\n",
    "\n",
    "    while signal_index*125+snippet_len < signal.shape[1]:\n",
    "    ####### Write batch file to disk #######\n",
    "\n",
    "      if batch_index == batch_size:\n",
    "        print('Batch ' + str(batch_num) + ' saved')\n",
    "\n",
    "        batch = scale_data(batch, scaler, snippet_len)\n",
    "\n",
    "        hf = h5py.File(save_path + '/' + 'Batch_{}'.format(batch_num)  + '.h5', 'w')\n",
    "        hf.create_dataset('data', data=batch)\n",
    "        hf.close()\n",
    "\n",
    "        batch_index = 0\n",
    "        batch_num += 1\n",
    "        batch = np.zeros((batch_size, snippet_len, channels))\n",
    "\n",
    "\n",
    "      if clean and signal_quality[signal_index] == 1:\n",
    "        batch[batch_index] = signal[:,signal_index*125 : signal_index*125+snippet_len].T\n",
    "        batch_index += 1\n",
    "      elif not clean:\n",
    "        batch[batch_index] = signal[:,signal_index*125 : signal_index*125+snippet_len].T\n",
    "        batch_index += 1\n",
    "        \n",
    "      signal_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 14231,
     "status": "ok",
     "timestamp": 1607683605793,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "mNE-8Oz9ayI6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NOT USED IN THE END\n",
    "It loads each recording on memory and then feeds the neural network with batches until the recording is over. \n",
    "Then it loads the next one.\n",
    "'''\n",
    "class Custom_Generator_preprocessed(tf.keras.utils.Sequence) :\n",
    "\n",
    "  def __init__(self, path, batch_size, shuffle=True) :\n",
    "\n",
    "    self.filenames = [path + '/' + name for name in os.listdir(path)]\n",
    "    self.shuffle = shuffle\n",
    "\n",
    "    self.current_file_index = 0\n",
    "    self.current_data = None\n",
    "    self.load_data(self.current_file_index)\n",
    "\n",
    "    self.slices = self.current_data.shape[0]//batch_size\n",
    "    self.in_file_indices = np.arange(self.slices)\n",
    "    self.step = self.current_data.shape[0]//self.slices\n",
    "\n",
    "    self.on_epoch_end()\n",
    "    self.load_data(self.current_file_index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def __len__(self) :\n",
    "    return self.slices*len(self.filenames)\n",
    "  \n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    'Updates indexes after each epoch'\n",
    "    self.current_file_index = 0\n",
    "\n",
    "    if self.shuffle is True:\n",
    "        np.random.shuffle(self.filenames)\n",
    "        np.random.shuffle(self.in_file_indices)\n",
    "\n",
    "\n",
    "  # preload data, I can do in class variables\n",
    "  def load_data(self, index):\n",
    "\n",
    "    name = self.filenames[index]\n",
    "\n",
    "    try:\n",
    "\n",
    "      file_signal = h5py.File(name, 'r')\n",
    "      data = file_signal['data'][()]\n",
    "      file_signal.close()\n",
    "\n",
    "      self.current_data = data\n",
    "      print('File {} loaded..'.format(name))\n",
    "\n",
    "    except KeyError as e:\n",
    "\n",
    "      print('File {} was broken. Next file fed'.format(name))\n",
    "      self.load_data(index+1, target)\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx) :\n",
    "\n",
    "    index_in_file = self.in_file_indices[idx%self.slices]\n",
    "\n",
    "    data = self.current_data[index_in_file*self.step : (index_in_file+1)*self.step]\n",
    "\n",
    "    if idx%self.slices == self.slices - 1:\n",
    "      self.current_file_index += 1\n",
    "      self.load_data(self.current_file_index)\n",
    "\n",
    "    return data, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 14222,
     "status": "ok",
     "timestamp": 1607683605795,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "D-ec8DrcazfB"
   },
   "outputs": [],
   "source": [
    "# generator = Custom_Generator_preprocessed('Data/fetal_quality_assessment/1250_clean_dataset', batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 14218,
     "status": "ok",
     "timestamp": 1607683605797,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "-hSD5Zbra2_g"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "It creates batch files with only the necessary data to reconstruct them. \n",
    "Meaning, it doesn't contain the overlapping data, it only filters the bad data\n",
    "It returns the recording with size (-1, 4) that will be transformed to the batch (batchsize, snippet_len, 4) after removing \n",
    "the low quality samples\n",
    "'''\n",
    "def preprocess_data(data_path, quality_path, save_path, scaler, batch_size, snippet_len):\n",
    "\n",
    "  filenames = os.listdir(data_path)\n",
    "\n",
    "  # recording length that we need to construct the signal if we do not count the low quality points\n",
    "  min_recording_len = batch_size*125+snippet_len\n",
    "  max_recording_len = 3*min_recording_len # arbitrary\n",
    "  batch_num = 0 # just for the naming of the files\n",
    "\n",
    "  for name in tqdm(filenames):\n",
    "    ##### Accessing data from files and preprocession ####\n",
    "\n",
    "    file_name = data_path + '/' + name\n",
    "    file_signal = h5py.File(file_name, 'r')\n",
    "    signal = file_signal['data'][()]\n",
    "    file_signal.close()\n",
    "\n",
    "    signal = scaler.transform(signal.T).T\n",
    "\n",
    "    quality_name = 'Data/fetal_quality_assessment/quality_files/' + name[:-12] + '.quality'\n",
    "    file_signal = h5py.File(quality_name, 'r')\n",
    "    signal_quality = file_signal['data'][()]\n",
    "    file_signal.close()\n",
    "    signal_quality = remove_nan(signal_quality)\n",
    "    signal_quality = signal_quality.flatten()\n",
    "\n",
    "    #### Creating batch files ######\n",
    "\n",
    "    # initialize batch\n",
    "    batch = np.zeros((max_recording_len, 4))\n",
    "    batch[0:snippet_len, :] = signal[:,0 : snippet_len].T\n",
    "\n",
    "    signal_index = snippet_len//125 - 1   # the index in the quality file, it starts after the first snippet_len\n",
    "    rejected_samples_indexes = []   # the indexes of the samples that will need to be rejected because they end in a low quality snippet\n",
    "    batch_index = 0   # in which index in the current sample we are\n",
    "    valid_samples = 0 # how many valid (with good quality ending) the current batch contains\n",
    "\n",
    "    if signal_quality[signal_index] == 0:\n",
    "      rejected_samples_indexes.append(batch_index)\n",
    "    else:\n",
    "      valid_samples += 1\n",
    "    \n",
    "    batch_index += 1\n",
    "\n",
    "    while (signal_index+1)*125+snippet_len < signal.shape[1]:\n",
    "\n",
    "    ####### Write batch file to disk #######\n",
    "      if valid_samples == batch_size:\n",
    "        # trim batch_zeros\n",
    "        batch = batch[:batch_index*125+snippet_len, : ]\n",
    "\n",
    "        hf = h5py.File(save_path + '/' + 'Batch_{}'.format(batch_num)  + '.h5', 'w')\n",
    "        hf.create_dataset('data', data=batch)\n",
    "        hf.create_dataset('rejected', data=np.array(rejected_samples_indexes))\n",
    "        hf.close()\n",
    "\n",
    "        print('Batch ' + str(batch_num) + ' saved')\n",
    "        batch_num += 1\n",
    "\n",
    "        # reinitialize\n",
    "        batch = np.zeros((max_recording_len, 4))\n",
    "        batch[0:snippet_len, :] = signal[:,signal_index*125 : signal_index*125+snippet_len].T\n",
    "\n",
    "        rejected_samples_indexes = []   # the indexes of the samples that will need to be rejected because they end in a low quality snippet\n",
    "        batch_index = 0   # in which index in the current sample we are\n",
    "        valid_samples = 0 # how many valid (with good quality ending) the current batch contains\n",
    "\n",
    "        if signal_quality[signal_index] == 1:\n",
    "          rejected_samples_indexes.append(batch_index)\n",
    "        else:\n",
    "          valid_samples += 1\n",
    "        \n",
    "        batch_index += 1\n",
    "    ##################################################\n",
    "\n",
    "      try:\n",
    "        # write 125 snippet to batch\n",
    "        batch[batch_index*125+snippet_len : (batch_index+1)*125+snippet_len, :] = \\\n",
    "                                              signal[:, signal_index*125+snippet_len : (signal_index+1)*125+snippet_len].T\n",
    "\n",
    "      except ValueError:\n",
    "        batch = np.append(batch, np.zeros((min_recording_len, 4)), axis=0)\n",
    "\n",
    "        batch[batch_index*125+snippet_len : (batch_index+1)*125+snippet_len, :] = \\\n",
    "                                              signal[:, signal_index*125+snippet_len : (signal_index+1)*125+snippet_len].T\n",
    "    \n",
    "      if signal_quality[signal_index] == 0:\n",
    "        rejected_samples_indexes.append(batch_index)\n",
    "      else:\n",
    "        valid_samples += 1\n",
    "\n",
    "      batch_index += 1\n",
    "      signal_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 14210,
     "status": "ok",
     "timestamp": 1607683605798,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "VdMZ-ZCYhwMN"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This creates a single file with three datasets:\n",
    "Data: a numpy array with shape (-1, 125, 4)\n",
    "bad_quality: a 1D numpy array containing the indices of bad data points\n",
    "recording_endings: 1D numpy array containing the indicies of the endings of recordings\n",
    "'''\n",
    "def create_single_file_dataset(data_path, quality_path, save_path, scaler=None):\n",
    "\n",
    "  filenames = os.listdir(data_path)\n",
    "\n",
    "  # find total length of data in 125 segments\n",
    "\n",
    "  total = 0\n",
    "  for name in tqdm(filenames):\n",
    "\n",
    "    if name[0] == '1':\n",
    "\n",
    "      quality_name = quality_path + '/' + name[:-12] + '.quality'\n",
    "      file_signal = h5py.File(quality_name, 'r')\n",
    "      signal_quality = file_signal['data'][()]\n",
    "      file_signal.close()\n",
    "      signal_quality = signal_quality.flatten()\n",
    "\n",
    "      total += len(signal_quality)\n",
    "\n",
    "\n",
    "  data = np.zeros((total, 125, 4), dtype=np.float16)\n",
    "  bad_quality = np.zeros(0, dtype=np.int)\n",
    "  recording_endings = []\n",
    "  index = 0\n",
    "\n",
    "\n",
    "  for name in tqdm(filenames):\n",
    "    ##### Accessing data from files and preprocession ####\n",
    "\n",
    "    file_name = data_path + '/' + name\n",
    "    file_signal = h5py.File(file_name, 'r')\n",
    "    signal = file_signal['data'][()]\n",
    "    file_signal.close()\n",
    "\n",
    "    # shape = (-1,4)\n",
    "    if scaler is not None:\n",
    "      signal = scaler.transform(signal.T)\n",
    "    else:\n",
    "      signal = signal.T\n",
    "\n",
    "    quality_name = quality_path + '/' + name[:-12] + '.quality'\n",
    "    file_signal = h5py.File(quality_name, 'r')\n",
    "    signal_quality = file_signal['data'][()]\n",
    "    file_signal.close()\n",
    "    signal_quality = remove_nan(signal_quality)\n",
    "    signal_quality = signal_quality.flatten()\n",
    "\n",
    "    # make it an integer multiple of 125\n",
    "    leftovers = signal.shape[0]%125\n",
    "    if leftovers != 0:\n",
    "      signal = signal[:-leftovers, :]\n",
    "      signal_quality = signal_quality[:-leftovers//125]\n",
    "\n",
    "    signal = np.reshape(signal, newshape=(-1, 125, 4)) \n",
    "\n",
    "    bad_quality_temp = np.where(signal_quality == 0)[0] + index\n",
    "\n",
    "    data[index : index + signal.shape[0]] = signal\n",
    "\n",
    "    index += signal.shape[0]\n",
    "\n",
    "    bad_quality = np.append(bad_quality, bad_quality_temp)\n",
    "    recording_endings.append(index)\n",
    "\n",
    "  data = data[:index]\n",
    "  hf = h5py.File(save_path, 'w')\n",
    "  hf.create_dataset('data', data=data)\n",
    "  hf.create_dataset('bad_quality', data=bad_quality)\n",
    "  hf.create_dataset('recording_endings', data=np.array(recording_endings))\n",
    "  hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 52522,
     "status": "ok",
     "timestamp": 1607683644128,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "nCN4wBHoAlLb"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This creates a single file with three datasets:\n",
    "Data: a numpy array with shape (-1, 125, 4)\n",
    "bad_quality: a 1D numpy array containing the indices of bad data points\n",
    "recording_endings: 1D numpy array containing the indicies of the endings of recordings\n",
    "'''\n",
    "def create_single_file_dataset_non_fetal(data_path, quality_path, save_path, scaler):\n",
    "\n",
    "  filenames = os.listdir(data_path)\n",
    "\n",
    "  # find total length of data in 125 segments\n",
    "\n",
    "  total = 0\n",
    "  for name in tqdm(filenames):\n",
    "\n",
    "    quality_name = quality_path + '/' + name[:-12] + '.quality'\n",
    "    file_signal = h5py.File(quality_name, 'r')\n",
    "    signal_quality = file_signal['data'][()]\n",
    "    file_signal.close()\n",
    "    signal_quality = signal_quality.flatten()\n",
    "\n",
    "    total += len(signal_quality)\n",
    "\n",
    "\n",
    "    data = np.zeros((total, 125, 4), dtype=np.float16)\n",
    "    recording_endings = []\n",
    "    index = 0\n",
    "\n",
    "\n",
    "  for name in tqdm(filenames):\n",
    "    ##### Accessing data from files and preprocession ####\n",
    "\n",
    "    file_name = data_path + '/' + name\n",
    "    file_signal = h5py.File(file_name, 'r')\n",
    "    signal = file_signal['data'][()]\n",
    "    file_signal.close()\n",
    "\n",
    "    signal = c_trim_zeros_NEMO(signal)\n",
    "\n",
    "    # shape = (-1,4)\n",
    "    signal = scaler.transform(signal.T)\n",
    "\n",
    "    # make it an integer multiple of 125\n",
    "    leftovers = signal.shape[0]%125\n",
    "    if leftovers != 0:\n",
    "      signal = signal[:-leftovers, :]\n",
    "\n",
    "    signal = np.reshape(signal, newshape=(-1, 125, 4)) \n",
    "\n",
    "    data[index : index + signal.shape[0]] = signal\n",
    "\n",
    "    index += signal.shape[0]\n",
    "\n",
    "    recording_endings.append(index)\n",
    "\n",
    "  data = data[:index]\n",
    "  hf = h5py.File(save_path, 'w')\n",
    "  hf.create_dataset('data', data=data)\n",
    "  hf.create_dataset('recording_endings', data=np.array(recording_endings))\n",
    "  hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 52514,
     "status": "ok",
     "timestamp": 1607683644130,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "IL5NmEdnBHzr"
   },
   "outputs": [],
   "source": [
    "# create_single_file_dataset_non_fetal('Data/non_fetal_signals/malePatients', 'Data/quality_files', \n",
    "#                                      'Data/non_fetal.h5', load(open('Models/ALL_scaler.pkl', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 52510,
     "status": "ok",
     "timestamp": 1607683644133,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "zVHwV8qo3ngb"
   },
   "outputs": [],
   "source": [
    "# create_single_file_dataset('Data/train', 'Data/quality_files', 'Data/train_folder.h5', load(open('Models/ALL_scaler.pkl', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 52502,
     "status": "ok",
     "timestamp": 1607683644135,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "uUhGyDnx0foS"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Reconstructs the recordings from the dataset file.\n",
    "INPUT:\n",
    "dataset, contains the data in shape (-1, 125,4) - all recordings appended\n",
    "bad_quality: it contains the indices of the low quality recordings\n",
    "recording_endings: it contains the indices of the ends of each recording\n",
    "OUTPUT\n",
    "recordings_labels: list of tuples. Each tuple contains the recording in shape (-1,125,4)\n",
    "and the labels with low quality -> 1 and high quality -> 0\n",
    "'''\n",
    "def reconstruct_recordings(dataset, bad_quality, recording_endings):\n",
    "  recordings_labels = []\n",
    "  for i in range(len(recording_endings)):\n",
    "    start = 0 if i==0 else recording_endings[i-1]\n",
    "    end = recording_endings[i]\n",
    "\n",
    "    recording = dataset[start:end,:,:]\n",
    "\n",
    "    bad_indices = bad_quality[np.where(bad_quality >= start)[0]]\n",
    "    bad_indices = bad_indices[np.where(bad_indices < end)[0]]\n",
    "    bad_indices = bad_indices - start\n",
    "\n",
    "    quality = np.zeros(end-start)\n",
    "    quality[bad_indices] = 1\n",
    "\n",
    "    recordings_labels.append((recording, quality))\n",
    "  \n",
    "  return recordings_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 52496,
     "status": "ok",
     "timestamp": 1607683644136,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "qBWKAJ7oCa3k"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Reconstructs the recordings from the dataset file, it doesn't need bad_quality indices because all are bad\n",
    "'''\n",
    "def reconstruct_recordings_non_fetal(dataset, recording_endings):\n",
    "  recordings_labels = []\n",
    "  for i in range(len(recording_endings)):\n",
    "    start = 0 if i==0 else recording_endings[i-1]\n",
    "    end = recording_endings[i]\n",
    "\n",
    "    recording = dataset[start:end,:,:]\n",
    "    labels = np.ones(recording.shape[0])\n",
    "\n",
    "    recordings_labels.append((recording, labels))\n",
    "\n",
    "  return recordings_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 52492,
     "status": "ok",
     "timestamp": 1607683644138,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "YATWgHQL1SJo"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "INPUT\n",
    "recordings_labels: list of tuples. Each tuple contains the recording in shape (-1,125,4)\n",
    "and the labels with low quality -> 1 and high quality -> 0\n",
    "autoencoder: the keras model autoencoder that will be used to reconstruct the recordings\n",
    "OUTPUT\n",
    "errors_labels: List of tuples with each tuple containing the reconstruction errors and the associated label (low quality ->1)\n",
    "'''\n",
    "def get_errors_per_recording(recordings_labels, autoencoder):\n",
    "\n",
    "  errors_labels = []\n",
    "\n",
    "  for i in range(len(recordings_labels)):\n",
    "    error = find_errors(recordings_labels[i][0], autoencoder)\n",
    "    errors_labels.append((error, recordings_labels[i][1]))\n",
    "\n",
    "  return errors_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 52489,
     "status": "ok",
     "timestamp": 1607683644140,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "1Sfetzklu99w"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "errors: the array containing all the errors of each 125 snippet. It should be flattened 1d\n",
    "lookback: how many\n",
    "return: output[i] = [error[t], error[t-1], ..., error[t-lookback-1] ]\n",
    "'''\n",
    "def create_features(errors, lookback):\n",
    "\n",
    "  output = np.zeros(shape=(len(errors), lookback))\n",
    "  for i in range(len(errors)):\n",
    "    output[i, :np.min([lookback, i+1])] = np.array([errors[i-j] for j in range(np.min([lookback, i+1]))])\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 52486,
     "status": "ok",
     "timestamp": 1607683644144,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "W7nM0Wu6FZJB"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "errors: the array containing all the errors of each 125 snippet. It should be flattened 1d\n",
    "lookback: how many\n",
    "return: output[i] = [error[t], error[t-1], ..., error[t-lookback-1] ]\n",
    "'''\n",
    "def create_features_2d(errors, lookback):\n",
    "\n",
    "  output = np.zeros(shape=(len(errors), lookback, 2))\n",
    "  for i in range(len(errors)):\n",
    "    output[i, :np.min([lookback, i+1]), :] = np.array([errors[i-j,:] for j in range(np.min([lookback, i+1]))])\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 52481,
     "status": "ok",
     "timestamp": 1607683644146,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "XR6OIWGz1luv"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "INPUT\n",
    "errors_labels: List of tuples with each tuple containing the reconstruction errors and the associated label (low quality ->1)\n",
    "lookback: how much historical data we will use\n",
    "OUTPUT\n",
    "data: processed data containing errors plus the lookback (overlapping)\n",
    "labels: associated labels\n",
    "'''\n",
    "def create_dataset_from_errors(error_labels, lookback):\n",
    "\n",
    "  data = np.zeros((0,lookback))\n",
    "  labels = np.empty(0)\n",
    "  for i in range(len(error_labels)):\n",
    "    errors = error_labels[i][0]\n",
    "    l = error_labels[i][1]\n",
    "    features = create_features(errors, lookback)\n",
    "\n",
    "    data = np.concatenate((data,features), axis=0)\n",
    "    labels = np.concatenate((labels,l))\n",
    "  \n",
    "  return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 52477,
     "status": "ok",
     "timestamp": 1607683644148,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "mCrnn6RdFQBe"
   },
   "outputs": [],
   "source": [
    "# same as before but now it also includes errors of the reconstruction on the frequency domain\n",
    "def create_dataset_from_errors_2d(error_labels, lookback):\n",
    "\n",
    "  data = np.zeros((0,lookback,2))\n",
    "  labels = np.empty(0)\n",
    "  for i in tqdm(range(len(error_labels))):\n",
    "    errors = error_labels[i][0]\n",
    "    l = error_labels[i][1]\n",
    "    features = create_features_2d(errors, lookback)\n",
    "\n",
    "    data = np.concatenate((data,features), axis=0)\n",
    "    labels = np.concatenate((labels,l))\n",
    "  \n",
    "  return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 52474,
     "status": "ok",
     "timestamp": 1607683644151,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "dBWqyrPeZysE"
   },
   "outputs": [],
   "source": [
    "# it subsamples the dataset so that it is balanced\n",
    "# ratio = majority/minority\n",
    "def balance_subsample(data, labels, ratio=1):\n",
    "\n",
    "  one_indices = np.where(labels == 1)[0]\n",
    "  zero_indices = np.where(labels == 0)[0]\n",
    "\n",
    "  indices = {0: zero_indices, 1: one_indices}\n",
    "\n",
    "  minority = 0 if len(zero_indices) < len(one_indices) else 1\n",
    "  majority = int(not minority)\n",
    "\n",
    "  minority_data = data[indices[minority]]\n",
    "  majority_data = data[indices[majority]]\n",
    "\n",
    "  # subsample\n",
    "  majority_data = majority_data[:int(ratio * minority_data.shape[0])]\n",
    "\n",
    "  minority_labels = np.zeros(minority_data.shape[0])\n",
    "  minority_labels[:] = minority\n",
    "\n",
    "  majority_labels = np.zeros(majority_data.shape[0])\n",
    "  majority_labels[:] = majority\n",
    "\n",
    "  new_data = np.concatenate((minority_data, majority_data), axis=0)\n",
    "  new_labels = np.concatenate((minority_labels, majority_labels), axis=0).flatten()\n",
    "\n",
    "  new_data, new_labels = shuffle(new_data, new_labels)\n",
    "  \n",
    "  return new_data, new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 52469,
     "status": "ok",
     "timestamp": 1607683644152,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "LudmS25FmjYa"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "It performs the fast fourier transform on our data and it returns the scaled magnitude of the fourier transform.\n",
    "It also balances time and space complexity, it makes the algorithm slower but it consumes less RAM (because we didn't have enough RAM \n",
    "to transform all the data at once)\n",
    "'''\n",
    "def fourier_lowmem(data, slices=15):\n",
    "\n",
    "  fourier = np.zeros((0, data.shape[1]//2,  data.shape[2]))\n",
    "  for i in tqdm(range(0, data.shape[0], data.shape[0]//slices)):\n",
    "    start = i\n",
    "    end = i + data.shape[0]//slices\n",
    "\n",
    "    f = np.abs(np.fft.fft(data[start:end], axis=1))[:,:data.shape[1]//2,:] * 1/data.shape[1]\n",
    "\n",
    "    fourier = np.concatenate((fourier, f), axis=0)\n",
    "    # clean_scipy_cache()\n",
    "\n",
    "  return fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 52466,
     "status": "ok",
     "timestamp": 1607683644154,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "nf_fGB522BHu"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "It performs the real fast fourier transform It  balances time and space complexity, \n",
    "it makes the algorithm slower but it consumes less RAM (because we didn't have enough RAM \n",
    "to transform all the data at once)\n",
    "'''\n",
    "def real_fourier_lowmem(data, slices=20):\n",
    "\n",
    "  fourier = np.zeros((data.shape[0], data.shape[1]//2 + 1, data.shape[2]))\n",
    "  for i in tqdm(range(0, data.shape[0], data.shape[0]//slices)):\n",
    "    start = i\n",
    "    end = i + data.shape[0]//slices\n",
    "\n",
    "    f = np.fft.rfft(data[start:end], axis=1)\n",
    "    # clean_scipy_cache()\n",
    "\n",
    "    fourier[start:end] = f\n",
    "\n",
    "  return fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 52463,
     "status": "ok",
     "timestamp": 1607683644156,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "MGFRqHqC2Xr1"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "It performs the inverse real fast fourier transform It  balances time and space complexity, \n",
    "it makes the algorithm slower but it consumes less RAM (because we didn't have enough RAM \n",
    "to transform all the data at once)\n",
    "'''\n",
    "def inv_real_fourier_lowmem(data, length, slices=20):\n",
    "\n",
    "  signal = np.zeros((data.shape[0], length, data.shape[2]))\n",
    "  for i in tqdm(range(0, data.shape[0], data.shape[0]//slices)):\n",
    "    start = i\n",
    "    end = i + data.shape[0]//slices\n",
    "\n",
    "    f = np.fft.irfft(data[start:end], n=length, axis=1)\n",
    "\n",
    "    signal[start:end] = f\n",
    "\n",
    "  return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 52458,
     "status": "ok",
     "timestamp": 1607683644157,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "NfyfoxCzFJWK"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "INPUT\n",
    "recordings_labels: list of tuples. Each tuple contains the recording in shape (-1,125,4)\n",
    "and the labels with low quality -> 1 and high quality -> 0\n",
    "OUTPUT\n",
    "list of tuples. Each tuple contains the scaled fourier transform recording in shape (-1,125,4)\n",
    "and the labels with low quality -> 1 and high quality -> 0\n",
    "'''\n",
    "def get_fourier(recordings_labels): \n",
    "\n",
    "  fourier_labels = []\n",
    "\n",
    "  for i in range(len(recordings_labels)):\n",
    "    r = recordings_labels[i][0]\n",
    "    l = recordings_labels[i][1]\n",
    "    f = np.abs(np.fft.fft(r, axis=1))[:,:r.shape[1]//2,:] * 1/r.shape[1]\n",
    "    fourier_labels.append((f,l))\n",
    "  \n",
    "  return fourier_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 52448,
     "status": "ok",
     "timestamp": 1607683644158,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "nmGCtGOgqFga"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create dataset that has the errors from both time and frequency domain\n",
    "'''\n",
    "def create_2d_dataset(recordings_labels, model_t, model_f, scaler_t=None, scaler_f=None):\n",
    "\n",
    "  errors_labels = []\n",
    "\n",
    "  for i in tqdm(range(len(recordings_labels))):\n",
    "    rec = recordings_labels[i][0]\n",
    "    lab = recordings_labels[i][1]\n",
    "    four = np.abs(np.fft.fft(rec, axis=1))[:,:rec.shape[1]//2,:] #* 1/rec.shape[1]\n",
    "\n",
    "    error_t = find_errors(rec, model_t)\n",
    "\n",
    "    error_f = find_errors(four, model_f)\n",
    "\n",
    "    if scaler_t != None and scaler_f != None:\n",
    "      error_t = scaler_t.transform(np.expand_dims(error_t, axis=1)).flatten()\n",
    "      error_f = scaler_f.transform(np.expand_dims(error_f, axis=1)).flatten()\n",
    "\n",
    "    error = np.vstack((error_t, error_f)).T\n",
    "\n",
    "    errors_labels.append((error, lab))\n",
    "\n",
    "  return errors_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 54368,
     "status": "ok",
     "timestamp": 1607683646084,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "yj9nFFJBMtE1"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "\n",
    "# Cython implementation of generating the batch\n",
    "cpdef cnp.ndarray c_get_batch(int index, cnp.ndarray data, int batch_len, int batch_size, \\\n",
    "                            int snippet_len, int window_step, cnp.ndarray bad_quality, cnp.ndarray recording_endings):\n",
    "\n",
    "    cdef int batch_index = 0\n",
    "    cdef int data_index = index*batch_len # beginning index of this batch\n",
    "    cdef cnp.ndarray batch = np.zeros((batch_size, snippet_len, 4))\n",
    "    cdef cnp.ndarray data_range\n",
    "\n",
    "    while batch_index < batch_size:\n",
    "      \n",
    "      data_range = np.arange(data_index, data_index + snippet_len//window_step)\n",
    "\n",
    "      if data_index + snippet_len//window_step not in bad_quality \\\n",
    "      and np.intersect1d(data_range, recording_endings).size == 0:\n",
    "\n",
    "        batch[batch_index] = np.reshape(data[data_index: data_index + snippet_len//window_step], (-1, 4))\n",
    "\n",
    "        batch_index += 1\n",
    "    \n",
    "      data_index += 1\n",
    "\n",
    "    return batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 54369,
     "status": "ok",
     "timestamp": 1607683646090,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "9Vl55S6_2ZG1"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "errors: the array containing all the errors of each 125 snippet. It should be flattened 1d\n",
    "lookback: how many\n",
    "return: output[i] = [error[t], error[t-1], ..., error[t-lookback-1] ]\n",
    "'''\n",
    "def create_lookback_2d(errors, lookback):\n",
    "\n",
    "  output = np.zeros(shape=(len(errors), lookback, 2))\n",
    "  for i in range(len(errors)):\n",
    "    output[i, :np.min([lookback, i+1]), :] = np.array([errors[i-j,:] for j in range(np.min([lookback, i+1]))])\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 54365,
     "status": "ok",
     "timestamp": 1607683646092,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "vB229N8-PrT1"
   },
   "outputs": [],
   "source": [
    "# NOT USED IN THE END\n",
    "# It loads all the data on the memory and then feeds the neural network with samples. Trying to find a balance between I/O operations and \n",
    "# preprocessing\n",
    "class Custom_Generator_one_file(tf.keras.utils.Sequence) :\n",
    "\n",
    "  def __init__(self, path, batch_size, snippet_len, window_step=125, shuffle=True) :\n",
    "\n",
    "    file_signal = h5py.File(path, 'r')\n",
    "    self.data = file_signal['data'][()]\n",
    "    self.bad_quality = file_signal['bad_quality'][()]\n",
    "    self.recording_endings = file_signal['recording_endings'][()]\n",
    "    file_signal.close()\n",
    "\n",
    "    self.shuffle = shuffle\n",
    "    self.window_step = window_step\n",
    "\n",
    "    self.batch_size = batch_size\n",
    "    self.snippet_len = snippet_len\n",
    "\n",
    "    # number of datapoints in a batch\n",
    "    self.batch_len = self.snippet_len//self.window_step + self.batch_size - 1\n",
    "    self.length = self.find_length()\n",
    "\n",
    "    self.indices = np.arange(self.length)\n",
    "    self.on_epoch_end()\n",
    "    \n",
    "  def __len__(self) :\n",
    "    return self.length\n",
    "\n",
    "  \n",
    "  def find_length(self):\n",
    "    length = (self.data.shape[0] - len(self.bad_quality) - len(self.recording_endings)*self.snippet_len//self.window_step)//self.batch_len\n",
    "    return length\n",
    "  \n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    'Updates indexes after each epoch'\n",
    "    if self.shuffle == True:\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "  @numba.jit(forceobj=True, fastmath=True)\n",
    "  def get_batch(self, index):\n",
    "\n",
    "    batch_index = 0\n",
    "    data_index = index*self.batch_len # beginning index of this batch\n",
    "    batch = np.zeros((self.batch_size, self.snippet_len, 4))\n",
    "\n",
    "    while batch_index < self.batch_size:\n",
    "      \n",
    "      data_range = np.arange(data_index, data_index + self.snippet_len//self.window_step)\n",
    "\n",
    "      if data_index + self.snippet_len//self.window_step not in self.bad_quality \\\n",
    "      and np.intersect1d(data_range, self.recording_endings).size == 0:\n",
    "        batch[batch_index] = np.reshape(self.data[data_index: data_index + self.snippet_len//self.window_step], (-1, 4))\n",
    "\n",
    "        batch_index += 1\n",
    "    \n",
    "      data_index += 1\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx) :\n",
    "\n",
    "    index = self.indices[idx]\n",
    "    # batch = self.get_batch(index)\n",
    "    batch = c_get_batch(index, self.data, self.batch_len, self.batch_size, self.snippet_len, \n",
    "                        self.window_step, self.bad_quality, self.recording_endings)\n",
    "\n",
    "    return batch, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 54366,
     "status": "ok",
     "timestamp": 1607683646103,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "1lPBet_1XLQL"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "function that returns consecutive high or low quality data\n",
    "length: segment length in # of data points\n",
    "wanted_quality:  (1 low, 0 high)\n",
    "recording: the recording with shape (-1,125,4)\n",
    "labels: the corresponding labels (1 low, 0 high)\n",
    "'''\n",
    "def consecutive_data(length, recording, labels, wanted_quality=0):\n",
    "\n",
    "  segments = []\n",
    "  signal_index = 0\n",
    "\n",
    "  segments_in_length = length//recording.shape[1]\n",
    "\n",
    "  while signal_index < len(labels):\n",
    "\n",
    "    current_segment = np.zeros((segments_in_length, recording.shape[1], recording.shape[2]))\n",
    "    current_segment_index = 0\n",
    "\n",
    "    while current_segment_index < segments_in_length:\n",
    "\n",
    "      if signal_index + current_segment_index < len(labels):\n",
    "\n",
    "        if wanted_quality == labels[signal_index + current_segment_index]:\n",
    "          current_segment[current_segment_index] = recording[signal_index + current_segment_index]\n",
    "        \n",
    "        else:\n",
    "          signal_index += 1\n",
    "          current_segment_index += 1\n",
    "          break\n",
    "        \n",
    "      else:\n",
    "        signal_index += 1\n",
    "        current_segment_index += 1\n",
    "        break\n",
    "\n",
    "      if current_segment_index+1 == segments_in_length:\n",
    "        segments.append(current_segment.reshape(1, length, recording.shape[2]))\n",
    "\n",
    "      signal_index += 1\n",
    "      current_segment_index += 1\n",
    "\n",
    "\n",
    "  segments_array = np.concatenate(segments, axis=0)\n",
    "  \n",
    "  return segments_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 54362,
     "status": "ok",
     "timestamp": 1607683646105,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "hClhWk6xG0vD"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function generates a dataset consisting of consecutive high quality segments of a specific length\n",
    "INPUT\n",
    "dataset: contains the data in shape (-1, 125,4) - all recordings appended\n",
    "bad_quality: it contains the indices of the low quality recordings\n",
    "recording_endings: it contains the indices of the ends of each recording\n",
    "length: The length of the segments of consecutive high quality data, it must be a multiple of 125\n",
    "how_many_files: Limits the number of files we will use, it accounts for memory limitations\n",
    "OUTPUT\n",
    "The dataset in shape (-1, length, channels)\n",
    "'''\n",
    "def consecutive_clean_dataset(dataset, bad_quality, recording_endings, length, how_many_files=60):\n",
    "\n",
    "  reconstructed = reconstruct_recordings(dataset, bad_quality, recording_endings)[:how_many_files]\n",
    "\n",
    "  # total_bad_quality = bad_quality.size\n",
    "  # total_good_quality = dataset.shape[0] - total_bad_quality\n",
    "  # total_size = int(total_good_quality * length/dataset.shape[1])\n",
    "  # segments = np.zeros((total_size, length, dataset.shape[2]))\n",
    "  # current_index = 0\n",
    "\n",
    "  segments = np.zeros((0, length, dataset.shape[2]))\n",
    "\n",
    "  for i in tqdm(range(len(reconstructed))):\n",
    "\n",
    "    recording = reconstructed[i][0]\n",
    "    labels = reconstructed[i][1]\n",
    "\n",
    "    s = consecutive_data(length, recording, labels)\n",
    "\n",
    "    segments = np.concatenate((segments, s), axis=0)\n",
    "\n",
    "    # segments[current_index : current_index+s.shape[0]] = s\n",
    "    # current_index += s.shape[0]\n",
    "\n",
    "  \n",
    "  return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 54355,
     "status": "ok",
     "timestamp": 1607683646106,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "xjkbhyhy_LAt"
   },
   "outputs": [],
   "source": [
    "# # Count how much data we have\n",
    "# filenames = os.listdir('Data/Clean/quality_files')\n",
    "\n",
    "# total = 0\n",
    "# for name in tqdm(filenames):\n",
    "\n",
    "#   if name[0] == '1':\n",
    "\n",
    "#     quality_path = 'Data/Clean/quality_files/' + name\n",
    "#     file_signal = h5py.File(quality_path, 'r')\n",
    "#     signal_quality = file_signal['data'][()]\n",
    "#     file_signal.close()\n",
    "#     signal_quality = signal_quality.flatten()\n",
    "\n",
    "#     total += len(signal_quality)\n",
    "\n",
    "# print('We have {} quality points, meaning {} datapoints'.format(str(total), str(total*125)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 54353,
     "status": "ok",
     "timestamp": 1607683646108,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "rTWYgWyngNV1"
   },
   "outputs": [],
   "source": [
    "# WE USED 72 FILES to create the scaler\n",
    "# # FIT SCALER \n",
    "\n",
    "# filenames = os.listdir(r'Data/fetal_quality_assessment/all_fetal_signals')\n",
    "# np.random.shuffle(filenames)\n",
    "# all_signals = np.zeros((4,0))\n",
    "# used_files = []\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "# for name in tqdm(filenames):\n",
    "\n",
    "#   file_signal = h5py.File(r'Data/fetal_quality_assessment/all_fetal_signals/{}'.format(name), 'r')\n",
    "#   signal = file_signal['data'][()]\n",
    "#   file_signal.close()\n",
    "\n",
    "#   all_signals = np.concatenate((all_signals, signal), axis=1)\n",
    "#   scaler.fit(all_signals.T)\n",
    "#   dump(scaler, open('ALL_scaler.pkl', 'wb'))\n",
    "\n",
    "#   used_files.append(name)\n",
    "#   print('We used %d files' % len(used_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 54350,
     "status": "ok",
     "timestamp": 1607683646111,
     "user": {
      "displayName": "Yannis Linardos",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64",
      "userId": "08892510110063016148"
     },
     "user_tz": -60
    },
    "id": "vZyx-ex1gCMC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNlVJ/k+bNmrq8pxy+6fcwU",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DataPreparation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
