{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"freq_domain_autoencoder.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPS0lvEAM3B86/LmdCp8dBv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bb236ada55b24883bf4b8ce7e702cfd3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a2d26bb9c3c043908e767f5d26eb0b3c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_31d2bbf052f44d278e494b0f9f9a0e48","IPY_MODEL_cea045b91ec545e3ba60226d805c81a9"]}},"a2d26bb9c3c043908e767f5d26eb0b3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31d2bbf052f44d278e494b0f9f9a0e48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dac73960df464493b271e3286a464da0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":21,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":21,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_248a8f615e994f2f8995da5777275820"}},"cea045b91ec545e3ba60226d805c81a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78b74d06d7bf43fb8b44283f82ab4963","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 21/21 [00:29&lt;00:00,  1.39s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e7103cc4d13464383e1c582572b193f"}},"dac73960df464493b271e3286a464da0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"248a8f615e994f2f8995da5777275820":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78b74d06d7bf43fb8b44283f82ab4963":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3e7103cc4d13464383e1c582572b193f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd957e1c0b0446bebee888b5346a4506":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1c5c12d15c164381bb04347b61f43092","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e9776a0f554547dc90f071958ee08dea","IPY_MODEL_16416d3a2ac64b90867ad825db1af699"]}},"1c5c12d15c164381bb04347b61f43092":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9776a0f554547dc90f071958ee08dea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0daa92ec095d470a806a5428a6ac489c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":16,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":16,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_494caefeaa884c9da5ed3a2bcb4fd05c"}},"16416d3a2ac64b90867ad825db1af699":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_938cc43e0a6f4ee3827010b676035d5f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 16/16 [00:23&lt;00:00,  1.50s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3400dd77cdde4f1caef81fb078ee53d2"}},"0daa92ec095d470a806a5428a6ac489c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"494caefeaa884c9da5ed3a2bcb4fd05c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"938cc43e0a6f4ee3827010b676035d5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3400dd77cdde4f1caef81fb078ee53d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"kM4B2Q_5W4XJ"},"source":["In this notebook, I created and trained the autoencoder in the frequency domain"]},{"cell_type":"code","metadata":{"id":"O6wD79qMShmI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606316563000,"user_tz":-60,"elapsed":23455,"user":{"displayName":"Yannis Linardos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64","userId":"08892510110063016148"}},"outputId":"99fa9b6b-6737-4935-e8e9-2cb66ae79234"},"source":["# Mount google drive\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","%cd gdrive/'My Drive'/Internship/Project"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n","/content/gdrive/My Drive/Internship/Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JLhSVWxoDg9u"},"source":["%run Code/Final/DataPreparation.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LmrQNqzKgClE"},"source":["%run Code/Final/Performance_metrics.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3tUwF1CSml3"},"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","import h5py\n","import os\n","from sklearn.preprocessing import RobustScaler\n","from pickle import dump, load\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","from tqdm.notebook import trange, tqdm\n","from tensorflow.keras.layers import Conv1D, Conv1DTranspose, LeakyReLU, ReLU, Activation, Dropout, PReLU, \\\n","                                    BatchNormalization, Flatten, Dense, Reshape, Input, AveragePooling1D, UpSampling1D\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"76YJydjSwIA5"},"source":["# load training data\n","file_signal = h5py.File('Data/train_folder.h5', 'r')\n","data = file_signal['data'][()]\n","bad_quality = file_signal['bad_quality'][()]\n","recording_endings = file_signal['recording_endings'][()]\n","file_signal.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oyT0Q4t_YOxd"},"source":["# separate normal from anomalous data\n","d_clean = np.delete(data, bad_quality, axis=0)\n","d_dirty = data[bad_quality]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SapAS9nswYYB","colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["bb236ada55b24883bf4b8ce7e702cfd3","a2d26bb9c3c043908e767f5d26eb0b3c","31d2bbf052f44d278e494b0f9f9a0e48","cea045b91ec545e3ba60226d805c81a9","dac73960df464493b271e3286a464da0","248a8f615e994f2f8995da5777275820","78b74d06d7bf43fb8b44283f82ab4963","3e7103cc4d13464383e1c582572b193f","cd957e1c0b0446bebee888b5346a4506","1c5c12d15c164381bb04347b61f43092","e9776a0f554547dc90f071958ee08dea","16416d3a2ac64b90867ad825db1af699","0daa92ec095d470a806a5428a6ac489c","494caefeaa884c9da5ed3a2bcb4fd05c","938cc43e0a6f4ee3827010b676035d5f","3400dd77cdde4f1caef81fb078ee53d2"]},"executionInfo":{"status":"ok","timestamp":1606316637031,"user_tz":-60,"elapsed":52870,"user":{"displayName":"Yannis Linardos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64","userId":"08892510110063016148"}},"outputId":"e0db67ed-9631-441d-fd31-4b0017fbeb03"},"source":["# Get the spectrogram data\n","fourier_clean = fourier_lowmem(d_clean, 20)\n","fourier_dirty = fourier_lowmem(d_dirty)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb236ada55b24883bf4b8ce7e702cfd3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd957e1c0b0446bebee888b5346a4506","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s3krUwvqyM4w"},"source":["# shuffle data and separate the to training and validation set\n","fourier_clean = shuffle(fourier_clean)\n","X_train = fourier_clean[:int(fourier_clean.shape[0]*0.7)]\n","X_test = fourier_clean[int(fourier_clean.shape[0]*0.7):]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwcVLShDjtPr"},"source":["class ConvAutoencoder:\n","  '''\n","  Based on https://www.pyimagesearch.com/2020/02/24/denoising-autoencoders-with-keras-tensorflow-and-deep-learning/\n","  kernel: The size of the convolutional kernels, chosen to be the same for simplicity\n","  filters: Number of filters/units the encoder and decoder will learn, respectively\n","  snippet_len: Length of the input signal (default 500/4=125).\n","  latentDim: Dimensionality of the latent-space representation.\n","  channels: the number of channels in the signal\n","  dropout: the dropout rate to be added in the convolutional layers\n","  '''\n","\n","  @staticmethod\n","  def build(kernel, filters, latentDim, dil=1, snippet_len=125,  channels=4, dropout=0.3): \n","\n","    # initialize the input shape to be \"channels last\" along with the channels dimension itself\n","    inputShape = (snippet_len, channels)\n","\n","    # define the input to the encoder\n","    inputs = Input(shape=inputShape)\n","\n","    x = inputs\n","    # loop over the number of filters\n","    for f in filters:\n","      x = Conv1D(f, kernel, padding=\"same\", dilation_rate=dil,\n","                #  kernel_regularizer='l1', bias_regularizer='l1',\n","                 )(x)\n","      x = PReLU()(x)\n","\n","      if dropout != 0:\n","        x = Dropout(dropout)(x)\n","\n","    # flatten the network and then construct our latent vector\n","    volumeSize = K.int_shape(x)\n","\n","    x = Flatten()(x)\n","    latent = Dense(latentDim)(x)\n","\n","    # build the encoder model\n","    encoder = Model(inputs, latent, name=\"encoder\")\n","\n","    # start building the decoder model which will accept the output of the encoder as its inputs\n","    latentInputs = Input(shape=(latentDim))\n","    x = Dense(np.prod(volumeSize[1:]))(latentInputs)\n","    x = Reshape((volumeSize[1], volumeSize[2]))(x)\n","\n","    # loop over our number of filters again, but this time in reverse order\n","    for f in filters[::-1]:\n","      x = Conv1DTranspose(f, kernel, padding=\"same\", dilation_rate=dil, \n","                          # kernel_regularizer='l1', bias_regularizer='l1',\n","                          )(x)\n","      x = PReLU()(x)\n","\n","      if dropout != 0:\n","        x = Dropout(dropout)(x)\n","\n","    # apply a single CONV_TRANSPOSE layer used to recover the original depth of the signal\n","    x = Conv1DTranspose(channels, kernel, padding=\"same\", dilation_rate=dil)(x)\n","    outputs = x\n","    \n","    # build the decoder model\n","    decoder = Model(latentInputs, outputs, name=\"decoder\")\n","\n","    # our autoencoder is the encoder + decoder\n","    autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\n","\n","    # return a 3-tuple of the encoder, decoder, and autoencoder\n","    return (encoder, decoder, autoencoder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3eDSJ_QwDrPu"},"source":["# define checkpoints\n","checkpoint_train = ModelCheckpoint('checkpoint_fourier_train.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n","checkpoint_val = ModelCheckpoint('checkpoint_fourier_val.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","\n","callbacks_list = [checkpoint_train, checkpoint_val]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HDPYKmRlACf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604924636988,"user_tz":-60,"elapsed":139002,"user":{"displayName":"Yannis Linardos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64","userId":"08892510110063016148"}},"outputId":"f6b3a72c-5e6e-44fb-9d88-528e6b175916"},"source":["# intialize the autoencoder\n","(encoder, decoder, autoencoder) = ConvAutoencoder.build(kernel=5, filters=(60, 30), latentDim=30, snippet_len=125//2, channels=4)\n","INIT_LR = 1e-4\n","EPOCHS = 150\n","b_size = 32\n","\n","opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","autoencoder.compile(loss=tf.keras.losses.mae, optimizer=opt)      \n","\n","autoencoder.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"autoencoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 62, 4)]           0         \n","_________________________________________________________________\n","encoder (Functional)         (None, 30)                71700     \n","_________________________________________________________________\n","decoder (Functional)         (None, 62, 4)             78034     \n","=================================================================\n","Total params: 149,734\n","Trainable params: 149,734\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cBVeS6UC0jQ8","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1604938194639,"user_tz":-60,"elapsed":11995054,"user":{"displayName":"Yannis Linardos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64","userId":"08892510110063016148"}},"outputId":"0627b99f-ce52-41cc-a9db-722686a37c39"},"source":["H = autoencoder.fit(x=X_train, y=X_train, batch_size=b_size, epochs=EPOCHS, \n","                    validation_data=(X_test, X_test), callbacks=callbacks_list, verbose=2) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","\n","Epoch 00001: loss improved from inf to 0.02266, saving model to checkpoint_fourier_train.h5\n","\n","Epoch 00001: val_loss improved from inf to 0.01922, saving model to checkpoint_fourier_val.h5\n","15696/15696 - 124s - loss: 0.0227 - val_loss: 0.0192\n","Epoch 2/150\n","\n","Epoch 00002: loss did not improve from 0.02266\n","\n","Epoch 00002: val_loss improved from 0.01922 to 0.01893, saving model to checkpoint_fourier_val.h5\n","15696/15696 - 123s - loss: 0.0228 - val_loss: 0.0189\n","Epoch 3/150\n","\n","Epoch 00003: loss improved from 0.02266 to 0.02108, saving model to checkpoint_fourier_train.h5\n","\n","Epoch 00003: val_loss improved from 0.01893 to 0.01855, saving model to checkpoint_fourier_val.h5\n","15696/15696 - 123s - loss: 0.0211 - val_loss: 0.0185\n","Epoch 4/150\n","\n","Epoch 00004: loss did not improve from 0.02108\n","\n","Epoch 00004: val_loss did not improve from 0.01855\n","15696/15696 - 123s - loss: 0.0213 - val_loss: 0.0200\n","Epoch 5/150\n","\n","Epoch 00005: loss improved from 0.02108 to 0.02073, saving model to checkpoint_fourier_train.h5\n","\n","Epoch 00005: val_loss did not improve from 0.01855\n","15696/15696 - 121s - loss: 0.0207 - val_loss: 0.0191\n","Epoch 6/150\n","\n","Epoch 00006: loss did not improve from 0.02073\n","\n","Epoch 00006: val_loss did not improve from 0.01855\n","15696/15696 - 119s - loss: 0.0218 - val_loss: 0.0189\n","Epoch 7/150\n","\n","Epoch 00007: loss did not improve from 0.02073\n","\n","Epoch 00007: val_loss did not improve from 0.01855\n","15696/15696 - 123s - loss: 0.0212 - val_loss: 0.0187\n","Epoch 8/150\n","\n","Epoch 00008: loss did not improve from 0.02073\n","\n","Epoch 00008: val_loss did not improve from 0.01855\n","15696/15696 - 121s - loss: 0.0223 - val_loss: 0.0188\n","Epoch 9/150\n","\n","Epoch 00009: loss did not improve from 0.02073\n","\n","Epoch 00009: val_loss did not improve from 0.01855\n","15696/15696 - 120s - loss: 0.0213 - val_loss: 0.0239\n","Epoch 10/150\n","\n","Epoch 00010: loss did not improve from 0.02073\n","\n","Epoch 00010: val_loss did not improve from 0.01855\n","15696/15696 - 121s - loss: 0.0211 - val_loss: 0.0186\n","Epoch 11/150\n","\n","Epoch 00011: loss did not improve from 0.02073\n","\n","Epoch 00011: val_loss did not improve from 0.01855\n","15696/15696 - 120s - loss: 0.0216 - val_loss: 0.0186\n","Epoch 12/150\n","\n","Epoch 00012: loss did not improve from 0.02073\n","\n","Epoch 00012: val_loss improved from 0.01855 to 0.01835, saving model to checkpoint_fourier_val.h5\n","15696/15696 - 120s - loss: 0.0208 - val_loss: 0.0184\n","Epoch 13/150\n","\n","Epoch 00013: loss did not improve from 0.02073\n","\n","Epoch 00013: val_loss did not improve from 0.01835\n","15696/15696 - 118s - loss: 0.0220 - val_loss: 0.0184\n","Epoch 14/150\n","\n","Epoch 00014: loss did not improve from 0.02073\n","\n","Epoch 00014: val_loss did not improve from 0.01835\n","15696/15696 - 117s - loss: 0.0212 - val_loss: 0.0184\n","Epoch 15/150\n","\n","Epoch 00015: loss did not improve from 0.02073\n","\n","Epoch 00015: val_loss did not improve from 0.01835\n","15696/15696 - 118s - loss: 0.0222 - val_loss: 0.0187\n","Epoch 16/150\n","\n","Epoch 00016: loss did not improve from 0.02073\n","\n","Epoch 00016: val_loss did not improve from 0.01835\n","15696/15696 - 117s - loss: 0.0225 - val_loss: 0.0190\n","Epoch 17/150\n","\n","Epoch 00017: loss did not improve from 0.02073\n","\n","Epoch 00017: val_loss did not improve from 0.01835\n","15696/15696 - 118s - loss: 0.0219 - val_loss: 0.0189\n","Epoch 18/150\n","\n","Epoch 00018: loss did not improve from 0.02073\n","\n","Epoch 00018: val_loss did not improve from 0.01835\n","15696/15696 - 117s - loss: 0.0210 - val_loss: 0.0185\n","Epoch 19/150\n","\n","Epoch 00019: loss improved from 0.02073 to 0.02054, saving model to checkpoint_fourier_train.h5\n","\n","Epoch 00019: val_loss did not improve from 0.01835\n","15696/15696 - 117s - loss: 0.0205 - val_loss: 0.0184\n","Epoch 20/150\n","\n","Epoch 00020: loss did not improve from 0.02054\n","\n","Epoch 00020: val_loss did not improve from 0.01835\n","15696/15696 - 118s - loss: 0.0218 - val_loss: 0.0191\n","Epoch 21/150\n","\n","Epoch 00021: loss did not improve from 0.02054\n","\n","Epoch 00021: val_loss did not improve from 0.01835\n","15696/15696 - 117s - loss: 0.0210 - val_loss: 0.0185\n","Epoch 22/150\n","\n","Epoch 00022: loss did not improve from 0.02054\n","\n","Epoch 00022: val_loss did not improve from 0.01835\n","15696/15696 - 115s - loss: 0.0211 - val_loss: 0.0192\n","Epoch 23/150\n","\n","Epoch 00023: loss did not improve from 0.02054\n","\n","Epoch 00023: val_loss did not improve from 0.01835\n","15696/15696 - 118s - loss: 0.0219 - val_loss: 0.0195\n","Epoch 24/150\n","\n","Epoch 00024: loss did not improve from 0.02054\n","\n","Epoch 00024: val_loss did not improve from 0.01835\n","15696/15696 - 119s - loss: 0.0213 - val_loss: 0.0185\n","Epoch 25/150\n","\n","Epoch 00025: loss did not improve from 0.02054\n","\n","Epoch 00025: val_loss did not improve from 0.01835\n","15696/15696 - 121s - loss: 0.0217 - val_loss: 0.0192\n","Epoch 26/150\n","\n","Epoch 00026: loss did not improve from 0.02054\n","\n","Epoch 00026: val_loss did not improve from 0.01835\n","15696/15696 - 119s - loss: 0.0210 - val_loss: 0.0185\n","Epoch 27/150\n","\n","Epoch 00027: loss did not improve from 0.02054\n","\n","Epoch 00027: val_loss did not improve from 0.01835\n","15696/15696 - 119s - loss: 0.0227 - val_loss: 0.0188\n","Epoch 28/150\n","\n","Epoch 00028: loss did not improve from 0.02054\n","\n","Epoch 00028: val_loss did not improve from 0.01835\n","15696/15696 - 120s - loss: 0.0213 - val_loss: 0.0205\n","Epoch 29/150\n","\n","Epoch 00029: loss did not improve from 0.02054\n","\n","Epoch 00029: val_loss did not improve from 0.01835\n","15696/15696 - 118s - loss: 0.0215 - val_loss: 0.0187\n","Epoch 30/150\n","\n","Epoch 00030: loss did not improve from 0.02054\n","\n","Epoch 00030: val_loss did not improve from 0.01835\n","15696/15696 - 118s - loss: 0.0206 - val_loss: 0.0192\n","Epoch 31/150\n","\n","Epoch 00031: loss did not improve from 0.02054\n","\n","Epoch 00031: val_loss did not improve from 0.01835\n","15696/15696 - 120s - loss: 0.0213 - val_loss: 0.0184\n","Epoch 32/150\n","\n","Epoch 00032: loss did not improve from 0.02054\n","\n","Epoch 00032: val_loss did not improve from 0.01835\n","15696/15696 - 118s - loss: 0.0213 - val_loss: 0.0186\n","Epoch 33/150\n","\n","Epoch 00033: loss did not improve from 0.02054\n","\n","Epoch 00033: val_loss improved from 0.01835 to 0.01834, saving model to checkpoint_fourier_val.h5\n","15696/15696 - 121s - loss: 0.0213 - val_loss: 0.0183\n","Epoch 34/150\n","\n","Epoch 00034: loss improved from 0.02054 to 0.02054, saving model to checkpoint_fourier_train.h5\n","\n","Epoch 00034: val_loss did not improve from 0.01834\n","15696/15696 - 118s - loss: 0.0205 - val_loss: 0.0196\n","Epoch 35/150\n","\n","Epoch 00035: loss did not improve from 0.02054\n","\n","Epoch 00035: val_loss did not improve from 0.01834\n","15696/15696 - 118s - loss: 0.0224 - val_loss: 0.0191\n","Epoch 36/150\n","\n","Epoch 00036: loss did not improve from 0.02054\n","\n","Epoch 00036: val_loss did not improve from 0.01834\n","15696/15696 - 120s - loss: 0.0215 - val_loss: 0.0184\n","Epoch 37/150\n","\n","Epoch 00037: loss did not improve from 0.02054\n","\n","Epoch 00037: val_loss did not improve from 0.01834\n","15696/15696 - 118s - loss: 0.0215 - val_loss: 0.0197\n","Epoch 38/150\n","\n","Epoch 00038: loss did not improve from 0.02054\n","\n","Epoch 00038: val_loss did not improve from 0.01834\n","15696/15696 - 119s - loss: 0.0210 - val_loss: 0.0188\n","Epoch 39/150\n","\n","Epoch 00039: loss did not improve from 0.02054\n","\n","Epoch 00039: val_loss did not improve from 0.01834\n","15696/15696 - 119s - loss: 0.0210 - val_loss: 0.0185\n","Epoch 40/150\n","\n","Epoch 00040: loss did not improve from 0.02054\n","\n","Epoch 00040: val_loss did not improve from 0.01834\n","15696/15696 - 119s - loss: 0.0212 - val_loss: 0.0186\n","Epoch 41/150\n","\n","Epoch 00041: loss did not improve from 0.02054\n","\n","Epoch 00041: val_loss did not improve from 0.01834\n","15696/15696 - 121s - loss: 0.0216 - val_loss: 0.0188\n","Epoch 42/150\n","\n","Epoch 00042: loss did not improve from 0.02054\n","\n","Epoch 00042: val_loss did not improve from 0.01834\n","15696/15696 - 119s - loss: 0.0218 - val_loss: 0.0187\n","Epoch 43/150\n","\n","Epoch 00043: loss did not improve from 0.02054\n","\n","Epoch 00043: val_loss did not improve from 0.01834\n","15696/15696 - 120s - loss: 0.0212 - val_loss: 0.0184\n","Epoch 44/150\n","\n","Epoch 00044: loss did not improve from 0.02054\n","\n","Epoch 00044: val_loss did not improve from 0.01834\n","15696/15696 - 121s - loss: 0.0213 - val_loss: 0.0186\n","Epoch 45/150\n","\n","Epoch 00045: loss improved from 0.02054 to 0.02045, saving model to checkpoint_fourier_train.h5\n","\n","Epoch 00045: val_loss improved from 0.01834 to 0.01828, saving model to checkpoint_fourier_val.h5\n","15696/15696 - 120s - loss: 0.0204 - val_loss: 0.0183\n","Epoch 46/150\n","\n","Epoch 00046: loss did not improve from 0.02045\n","\n","Epoch 00046: val_loss did not improve from 0.01828\n","15696/15696 - 121s - loss: 0.0206 - val_loss: 0.0184\n","Epoch 47/150\n","\n","Epoch 00047: loss did not improve from 0.02045\n","\n","Epoch 00047: val_loss did not improve from 0.01828\n","15696/15696 - 120s - loss: 0.0208 - val_loss: 0.0190\n","Epoch 48/150\n","\n","Epoch 00048: loss did not improve from 0.02045\n","\n","Epoch 00048: val_loss did not improve from 0.01828\n","15696/15696 - 122s - loss: 0.0215 - val_loss: 0.0184\n","Epoch 49/150\n","\n","Epoch 00049: loss did not improve from 0.02045\n","\n","Epoch 00049: val_loss did not improve from 0.01828\n","15696/15696 - 123s - loss: 0.0220 - val_loss: 0.0183\n","Epoch 50/150\n","\n","Epoch 00050: loss did not improve from 0.02045\n","\n","Epoch 00050: val_loss did not improve from 0.01828\n","15696/15696 - 121s - loss: 0.0214 - val_loss: 0.0184\n","Epoch 51/150\n","\n","Epoch 00051: loss did not improve from 0.02045\n","\n","Epoch 00051: val_loss did not improve from 0.01828\n","15696/15696 - 123s - loss: 0.0206 - val_loss: 0.0187\n","Epoch 52/150\n","\n","Epoch 00052: loss did not improve from 0.02045\n","\n","Epoch 00052: val_loss did not improve from 0.01828\n","15696/15696 - 122s - loss: 0.0220 - val_loss: 0.0193\n","Epoch 53/150\n","\n","Epoch 00053: loss did not improve from 0.02045\n","\n","Epoch 00053: val_loss did not improve from 0.01828\n","15696/15696 - 122s - loss: 0.0208 - val_loss: 0.0185\n","Epoch 54/150\n","\n","Epoch 00054: loss did not improve from 0.02045\n","\n","Epoch 00054: val_loss improved from 0.01828 to 0.01825, saving model to checkpoint_fourier_val.h5\n","15696/15696 - 123s - loss: 0.0212 - val_loss: 0.0183\n","Epoch 55/150\n","\n","Epoch 00055: loss did not improve from 0.02045\n","\n","Epoch 00055: val_loss did not improve from 0.01825\n","15696/15696 - 122s - loss: 0.0214 - val_loss: 0.0183\n","Epoch 56/150\n","\n","Epoch 00056: loss did not improve from 0.02045\n","\n","Epoch 00056: val_loss did not improve from 0.01825\n","15696/15696 - 123s - loss: 0.0215 - val_loss: 0.0190\n","Epoch 57/150\n","\n","Epoch 00057: loss did not improve from 0.02045\n","\n","Epoch 00057: val_loss did not improve from 0.01825\n","15696/15696 - 122s - loss: 0.0210 - val_loss: 0.0192\n","Epoch 58/150\n","\n","Epoch 00058: loss did not improve from 0.02045\n","\n","Epoch 00058: val_loss did not improve from 0.01825\n","15696/15696 - 122s - loss: 0.0214 - val_loss: 0.0183\n","Epoch 59/150\n","\n","Epoch 00059: loss did not improve from 0.02045\n","\n","Epoch 00059: val_loss did not improve from 0.01825\n","15696/15696 - 123s - loss: 0.0211 - val_loss: 0.0187\n","Epoch 60/150\n","\n","Epoch 00060: loss did not improve from 0.02045\n","\n","Epoch 00060: val_loss did not improve from 0.01825\n","15696/15696 - 122s - loss: 0.0211 - val_loss: 0.0185\n","Epoch 61/150\n","\n","Epoch 00061: loss did not improve from 0.02045\n","\n","Epoch 00061: val_loss did not improve from 0.01825\n","15696/15696 - 124s - loss: 0.0209 - val_loss: 0.0184\n","Epoch 62/150\n","\n","Epoch 00062: loss did not improve from 0.02045\n","\n","Epoch 00062: val_loss did not improve from 0.01825\n","15696/15696 - 122s - loss: 0.0211 - val_loss: 0.0186\n","Epoch 63/150\n","\n","Epoch 00063: loss did not improve from 0.02045\n","\n","Epoch 00063: val_loss did not improve from 0.01825\n","15696/15696 - 122s - loss: 0.0214 - val_loss: 0.0185\n","Epoch 64/150\n","\n","Epoch 00064: loss did not improve from 0.02045\n","\n","Epoch 00064: val_loss did not improve from 0.01825\n","15696/15696 - 124s - loss: 0.0215 - val_loss: 0.0187\n","Epoch 65/150\n","\n","Epoch 00065: loss did not improve from 0.02045\n","\n","Epoch 00065: val_loss improved from 0.01825 to 0.01816, saving model to checkpoint_fourier_val.h5\n","15696/15696 - 122s - loss: 0.0212 - val_loss: 0.0182\n","Epoch 66/150\n","\n","Epoch 00066: loss did not improve from 0.02045\n","\n","Epoch 00066: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0212 - val_loss: 0.0196\n","Epoch 67/150\n","\n","Epoch 00067: loss did not improve from 0.02045\n","\n","Epoch 00067: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0218 - val_loss: 0.0191\n","Epoch 68/150\n","\n","Epoch 00068: loss did not improve from 0.02045\n","\n","Epoch 00068: val_loss did not improve from 0.01816\n","15696/15696 - 121s - loss: 0.0214 - val_loss: 0.0185\n","Epoch 69/150\n","\n","Epoch 00069: loss did not improve from 0.02045\n","\n","Epoch 00069: val_loss did not improve from 0.01816\n","15696/15696 - 124s - loss: 0.0211 - val_loss: 0.0184\n","Epoch 70/150\n","\n","Epoch 00070: loss improved from 0.02045 to 0.02042, saving model to checkpoint_fourier_train.h5\n","\n","Epoch 00070: val_loss did not improve from 0.01816\n","15696/15696 - 121s - loss: 0.0204 - val_loss: 0.0183\n","Epoch 71/150\n","\n","Epoch 00071: loss did not improve from 0.02042\n","\n","Epoch 00071: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0212 - val_loss: 0.0184\n","Epoch 72/150\n","\n","Epoch 00072: loss did not improve from 0.02042\n","\n","Epoch 00072: val_loss did not improve from 0.01816\n","15696/15696 - 123s - loss: 0.0226 - val_loss: 0.0183\n","Epoch 73/150\n","\n","Epoch 00073: loss did not improve from 0.02042\n","\n","Epoch 00073: val_loss did not improve from 0.01816\n","15696/15696 - 121s - loss: 0.0206 - val_loss: 0.0185\n","Epoch 74/150\n","\n","Epoch 00074: loss did not improve from 0.02042\n","\n","Epoch 00074: val_loss did not improve from 0.01816\n","15696/15696 - 123s - loss: 0.0206 - val_loss: 0.0185\n","Epoch 75/150\n","\n","Epoch 00075: loss did not improve from 0.02042\n","\n","Epoch 00075: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0209 - val_loss: 0.0184\n","Epoch 76/150\n","\n","Epoch 00076: loss did not improve from 0.02042\n","\n","Epoch 00076: val_loss did not improve from 0.01816\n","15696/15696 - 121s - loss: 0.0213 - val_loss: 0.0184\n","Epoch 77/150\n","\n","Epoch 00077: loss did not improve from 0.02042\n","\n","Epoch 00077: val_loss did not improve from 0.01816\n","15696/15696 - 123s - loss: 0.0207 - val_loss: 0.0182\n","Epoch 78/150\n","\n","Epoch 00078: loss did not improve from 0.02042\n","\n","Epoch 00078: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0214 - val_loss: 0.0184\n","Epoch 79/150\n","\n","Epoch 00079: loss did not improve from 0.02042\n","\n","Epoch 00079: val_loss did not improve from 0.01816\n","15696/15696 - 123s - loss: 0.0210 - val_loss: 0.0183\n","Epoch 80/150\n","\n","Epoch 00080: loss did not improve from 0.02042\n","\n","Epoch 00080: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0215 - val_loss: 0.0185\n","Epoch 81/150\n","\n","Epoch 00081: loss did not improve from 0.02042\n","\n","Epoch 00081: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0214 - val_loss: 0.0186\n","Epoch 82/150\n","\n","Epoch 00082: loss improved from 0.02042 to 0.02028, saving model to checkpoint_fourier_train.h5\n","\n","Epoch 00082: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0203 - val_loss: 0.0182\n","Epoch 83/150\n","\n","Epoch 00083: loss did not improve from 0.02028\n","\n","Epoch 00083: val_loss did not improve from 0.01816\n","15696/15696 - 121s - loss: 0.0216 - val_loss: 0.0183\n","Epoch 84/150\n","\n","Epoch 00084: loss did not improve from 0.02028\n","\n","Epoch 00084: val_loss did not improve from 0.01816\n","15696/15696 - 123s - loss: 0.0218 - val_loss: 0.0203\n","Epoch 85/150\n","\n","Epoch 00085: loss improved from 0.02028 to 0.02016, saving model to checkpoint_fourier_train.h5\n","\n","Epoch 00085: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0202 - val_loss: 0.0183\n","Epoch 86/150\n","\n","Epoch 00086: loss did not improve from 0.02016\n","\n","Epoch 00086: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0210 - val_loss: 0.0184\n","Epoch 87/150\n","\n","Epoch 00087: loss did not improve from 0.02016\n","\n","Epoch 00087: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0210 - val_loss: 0.0197\n","Epoch 88/150\n","\n","Epoch 00088: loss did not improve from 0.02016\n","\n","Epoch 00088: val_loss did not improve from 0.01816\n","15696/15696 - 122s - loss: 0.0206 - val_loss: 0.0185\n","Epoch 89/150\n","\n","Epoch 00089: loss did not improve from 0.02016\n","\n","Epoch 00089: val_loss did not improve from 0.01816\n","15696/15696 - 123s - loss: 0.0213 - val_loss: 0.0197\n","Epoch 90/150\n","\n","Epoch 00090: loss did not improve from 0.02016\n","\n","Epoch 00090: val_loss did not improve from 0.01816\n","15696/15696 - 120s - loss: 0.0217 - val_loss: 0.0186\n","Epoch 91/150\n","\n","Epoch 00091: loss did not improve from 0.02016\n","\n","Epoch 00091: val_loss did not improve from 0.01816\n","15696/15696 - 121s - loss: 0.0217 - val_loss: 0.0191\n","Epoch 92/150\n","\n","Epoch 00092: loss did not improve from 0.02016\n","\n","Epoch 00092: val_loss did not improve from 0.01816\n","15696/15696 - 123s - loss: 0.0209 - val_loss: 0.0183\n","Epoch 93/150\n","\n","Epoch 00093: loss did not improve from 0.02016\n","\n","Epoch 00093: val_loss did not improve from 0.01816\n","15696/15696 - 123s - loss: 0.0205 - val_loss: 0.0184\n","Epoch 94/150\n","\n","Epoch 00094: loss did not improve from 0.02016\n","\n","Epoch 00094: val_loss did not improve from 0.01816\n","15696/15696 - 123s - loss: 0.0214 - val_loss: 0.0188\n","Epoch 95/150\n","\n","Epoch 00095: loss did not improve from 0.02016\n","\n","Epoch 00095: val_loss improved from 0.01816 to 0.01814, saving model to checkpoint_fourier_val.h5\n","15696/15696 - 123s - loss: 0.0209 - val_loss: 0.0181\n","Epoch 96/150\n","\n","Epoch 00096: loss did not improve from 0.02016\n","\n","Epoch 00096: val_loss did not improve from 0.01814\n","15696/15696 - 122s - loss: 0.0207 - val_loss: 0.0183\n","Epoch 97/150\n","\n","Epoch 00097: loss did not improve from 0.02016\n","\n","Epoch 00097: val_loss did not improve from 0.01814\n","15696/15696 - 123s - loss: 0.0214 - val_loss: 0.0183\n","Epoch 98/150\n","\n","Epoch 00098: loss did not improve from 0.02016\n","\n","Epoch 00098: val_loss did not improve from 0.01814\n","15696/15696 - 122s - loss: 0.0214 - val_loss: 0.0184\n","Epoch 99/150\n","\n","Epoch 00099: loss did not improve from 0.02016\n","\n","Epoch 00099: val_loss did not improve from 0.01814\n","15696/15696 - 122s - loss: 0.0210 - val_loss: 0.0186\n","Epoch 100/150\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-e6511ad6e92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m H = autoencoder.fit(x=X_train, y=X_train, batch_size=b_size, epochs=EPOCHS, steps_per_epoch=steps,\n\u001b[0;32m----> 2\u001b[0;31m                     validation_data=(X_test, X_test), callbacks=callbacks_list, verbose=2) \n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"L67SDYoAMRYe"},"source":["fourier_clean = shuffle(fourier_clean)\n","fourier_dirty = shuffle(fourier_dirty)\n","fourier_clean = fourier_clean[:50000]\n","fourier_dirty = fourier_dirty[:50000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rrYGSqwLc5I"},"source":["clean_errors = find_errors(fourier_clean, autoencoder)\n","anom_errors = find_errors(fourier_dirty, autoencoder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAfxe2Ui4yPw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604303409390,"user_tz":-60,"elapsed":456,"user":{"displayName":"Yannis Linardos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64","userId":"08892510110063016148"}},"outputId":"243fcb44-f744-444d-87a6-997830fc8e12"},"source":["print('mean clean error = %.4f, std clean error = %.4f\\nmean anom error = %.4f, std anom error = %.4f'\n","                              % (np.mean(clean_errors), np.std(clean_errors), np.mean(anom_errors), np.std(anom_errors))                              )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean clean error = 0.0073, std clean error = 0.1148\n","mean anom error = 0.0038, std anom error = 0.0200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mL4NRBIlDdOk"},"source":["original = fourier_dirty\n","reconstructed = autoencoder.predict(original)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wH_UpihuF1qo","colab":{"base_uri":"https://localhost:8080/","height":585},"executionInfo":{"status":"ok","timestamp":1605001813411,"user_tz":-60,"elapsed":10209,"user":{"displayName":"Yannis Linardos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64","userId":"08892510110063016148"}},"outputId":"5fde74b8-a4af-4001-a407-11eb7ac9e01a"},"source":["# Plot the spectrograms\n","N = 125\n","\n","\n","f = np.fft.fftfreq(N, 1/500)[:N//2] # 500 Hz sampling rate\n","\n","id = 10 # pick a segment\n","channel = 0\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(8,8))\n","ax1.bar(f, original[id,:,channel], width=2, label='original')\n","ax1.legend()\n","ax1.set_ylabel(\"Amplitude\")\n","ax1.set_xlabel(\"Frequency [Hz]\")\n","ax2.bar(f, np.abs(reconstructed[id,:,channel]), width=2, label='reconstructed')\n","ax2.legend()\n","ax2.set_ylabel(\"Amplitude\")\n","ax2.set_xlabel(\"Frequency [Hz]\")\n","\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x576 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"jEOMb_ws16cP"},"source":["original_d = fourier_clean\n","reconstructed_d = autoencoder.predict(original_d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AS4DEV-K16cj","colab":{"base_uri":"https://localhost:8080/","height":585},"executionInfo":{"status":"ok","timestamp":1606317163371,"user_tz":-60,"elapsed":1163,"user":{"displayName":"Yannis Linardos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdHpp2EPBdRTE4ybMH7n8FIGwky_EWvQpgH1B_6Q=s64","userId":"08892510110063016148"}},"outputId":"a231d713-586d-41e2-916f-73db5b995e80"},"source":["# Plot the spectrograms\n","N = 125\n","\n","\n","f = np.fft.fftfreq(N, 1/500)[:N//2] # 500 Hz sampling rate\n","\n","id = 10 # pick a segment\n","channel = 0\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(8,8))\n","ax1.bar(f, original_d[id,:,channel], width=2, label='original')\n","ax1.legend()\n","ax1.set_ylabel(\"Amplitude\")\n","ax1.set_xlabel(\"Frequency [Hz]\")\n","ax2.bar(f, np.abs(reconstructed_d[id,:,channel]), width=2, label='reconstructed')\n","ax2.legend()\n","ax2.set_ylabel(\"Amplitude\")\n","ax2.set_xlabel(\"Frequency [Hz]\")\n","\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x576 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"YVJyKdP-B70W"},"source":[""],"execution_count":null,"outputs":[]}]}