{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GANs.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOXNicMPSI3FvXNFVQ4a8jF"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UmZ08ESnwwig"},"source":["This notebook is like a module containing all my GAN implementations"]},{"cell_type":"code","metadata":{"id":"bBr2VpQrzmW7"},"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","from tqdm.notebook import trange, tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from pickle import load, dump\n","from scipy.optimize import minimize\n","\n","from tensorflow.keras.layers import  LeakyReLU, ReLU, PReLU, Activation, Dropout, BatchNormalization, Dense, \\\n","                                  Input, Conv1D, MaxPool1D, AveragePooling1D, Flatten, LSTM, Reshape, Conv1DTranspose\n","from tensorflow.keras.models import Model, Sequential, load_model, model_from_json\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.optimizers import Adam, RMSprop \n","from tensorflow.keras.utils import Progbar\n","from tensorflow.keras.constraints import Constraint\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BBoqJ2MyzEzW"},"source":["#  Mount google drive\r\n","if __name__ == '__main__' and '__file__' not in globals():\r\n","  from google.colab import drive\r\n","  drive.mount('/content/gdrive/')\r\n","  %cd gdrive/'My Drive'/Internship/Project"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLYnIHwmDkCO"},"source":["%run Code/Final/DataPreparation.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbUFlFaEFqgb"},"source":["%run Code/Final/Performance_metrics.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zUPoMrPZx43p"},"source":["*limeGAN*"]},{"cell_type":"code","metadata":{"id":"If2-MW5ipsIy"},"source":["# transform a complex number from polar to cartesian coordinates\n","def polar2cartesian(radii, angles):\n","    return radii * np.exp(1j*angles)\n","\n","# transform a complex number from cartesian to polar coordinates\n","def cartesian2polar(x):\n","    return np.abs(x), np.angle(x)\n","\n","# It takes as input a signal in the time domain (shape (-1, snippet_len, channels))\n","# and returns it in the frequency domain as in the output of the limeGAN (shape (-1, snippet_len//2+1, 2*channels))\n","def signal_2_fourier(signal):\n","  # freq = np.fft.fft(signal, axis=1)\n","  freq = np.fft.rfft(signal, axis=1)\n","\n","  radii, angles = cartesian2polar(freq)\n","\n","  # we have that angle and radius are symmetric if we exclude element 0\n","  # radii = radii[:,:signal.shape[1]//2+1,:]\n","  # angles = angles[:,:signal.shape[1]//2+1,:]\n","\n","  output = np.concatenate((radii, angles), axis=2)\n","\n","  return output\n","\n","# Inverse of the previous operation. From the output of the limeGAN to a signal in the time domain\n","def fourier_2_signal(freq, length):\n","\n","  radii = freq[:,:,:freq.shape[2]//2]\n","  angles = freq[:,:,freq.shape[2]//2:]\n","\n","  # unravel the symmetry (-1,125,4)\n","  # radii = np.concatenate((radii, np.flip(radii[:,1:,:], axis=1)), axis=1)\n","  # angles = np.concatenate((angles, -1*np.flip(angles[:,1:,:], axis=1)), axis=1)\n","\n","  # (-1,125,4)\n","  cartesian = polar2cartesian(radii, angles)\n","\n","  # signal = np.fft.ifft(cartesian, axis=1)\n","  signal = np.fft.irfft(cartesian, n=length, axis=1)\n","\n","\n","  return signal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RX9-Wm_g7_cl"},"source":["# used in output of the generator of the limeGAN\n","def custom_activation(x):\n","\n","  channels = K.shape(x)[2]\n","  r = x[:,:,:channels//2]\n","  a = x[:,:,channels//2:]\n","\n","  r = K.abs(r)  # radius cannot be negative\n","\n","  a = K.tanh(a) * K.constant(np.pi)   # angle between -pi and pi\n","\n","  out = K.concatenate((r, a), axis=2)\n","\n","  return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SwsmG23TeBNV"},"source":["# Scatter plot that we use for the anomalies. The only thing that changes is the ylablel\n","# y_likelihoods is the anomaly score\n","def scatter_GANs(y_true, y_likelihoods):\n","\n","  good_indices = np.where(y_true == 0)[0]\n","  bad_indices = np.where(y_true == 1)[0]\n","  good_points = y_likelihoods[good_indices]\n","  bad_points = y_likelihoods[bad_indices]\n","\n","  plt.figure(figsize=(16,10))\n","  plt.scatter(good_indices, good_points, label='hign quality', c='b', marker='.')\n","  plt.scatter(bad_indices, bad_points, label='low quality', c='r', marker='.')\n","  # plt.ylim(0,10000)\n","  plt.ylabel(\"Anomaly Score\")\n","  plt.xlabel(\"Data point index\")\n","\n","  plt.legend()\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VaRCaXPSBGA"},"source":["'''\n","Initialization of the limeGAN. It contains a G and a D, both convolutional. For simplicity, the kernel size is the same everywhere.\n","kernel: kernel size (int)\n","gen_layers: layers of generator (int)\n","dis_layers: layers of discriminator (int)\n","latentDim: dimension of the latent space (int)\n","depth: After the latent vector generation, we initialize a depth as a second dimension which will be decreased by layer and \n","will end up being the channel dimension (int)\n","dil: dilation rate\n","snippet_len: length of the segment we will generate\n","channels: the number of the channels\n","dropout: the dropout rate that will be used at each layer\n","INIT_LR: initial learning rate. We use the same in G and D\n","DECAY: weight decay. We use the same in G and D\n","''' \n","class limeGAN:\n","  def __init__(self, kernel, gen_layers, dis_layers, latentDim, depth, dil=1, snippet_len=125,  \n","               channels=4, dropout=None, INIT_LR=1e-5, DECAY=6e-8):\n","\n","    self.kernel = kernel\n","    self.gen_layers = gen_layers\n","    self.dis_layers = dis_layers\n","    self.latentDim = latentDim\n","    self.depth = depth\n","    self.dil = dil\n","    self.snippet_len = snippet_len\n","    self.channels = channels\n","    self.dropout = dropout\n","\n","    self.INIT_LR = INIT_LR\n","    self.DECAY = DECAY\n","\n","    self.G = self.generator()\n","    self.D_uncompiled = self.discriminator()\n","\n","    self.D = self.discriminator_compiled(self.D_uncompiled)\n","    self.Adversarial = self.adversarial_model(self.G, self.D_uncompiled)\n","\n","\n","  '''\n","  It saves the GAN to storage in the file \"filename.model\"\n","  '''\n","  def save(self, filename):\n","    d = {\n","        'kernel' : self.kernel,\n","        'gen_layers' : self.gen_layers, \n","        'dis_layers' : self.dis_layers, \n","        'latentDim' : self.latentDim,\n","        'depth'  : self.depth,\n","        'dil' :self.dil,\n","         'INIT_LR' : self.INIT_LR,\n","         'DECAY' : self.DECAY,\n","        'snippet_len' : self.snippet_len,\n","        'channels' : self.channels,\n","        'dropout' : self.dropout,\n","         'G_json' : self.G.to_json(),\n","         'G_weights' : self.G.get_weights(),\n","          'D_json' : self.D_uncompiled.to_json(),\n","         'D_weights' : self.D_uncompiled.get_weights()\n","         }\n","\n","    dump(d, open(filename + '.model', 'wb'))\n","\n","  '''\n","  Static method. We can load a limeGAN saved using the previous method.\n","  '''\n","  @staticmethod\n","  def load(filename):\n","    d = load(open(filename + '.model', 'rb'))\n","\n","    gan = limeGAN(d['kernel'], d['gen_layers'], d['dis_layers'], d['latentDim'], \n","              d['depth'], d['dil'], d['snippet_len'],  d['channels'], d['dropout'], d['INIT_LR'], d['DECAY'])\n","    \n","\n","    G = model_from_json(d['G_json'])\n","    G.set_weights(d['G_weights'])\n","    gan.G = G\n","\n","    D_uncompiled = model_from_json(d['D_json'])\n","    D_uncompiled.set_weights(d['D_weights'])\n","    gan.D_uncompiled = D_uncompiled\n","\n","    gan.D = gan.discriminator_compiled(D_uncompiled)\n","    gan.Adversarial = gan.adversarial_model(G, D_uncompiled)\n","\n","    return gan\n","\n","\n","  # It generates signals in the frequency domain as explained in the report\n","  def generator(self):\n","\n","      output_len = self.snippet_len//2+1    \n","\n","      inputs = Input(shape=(self.latentDim,))\n","\n","      x = Dense(output_len * self.depth)(inputs) \n","\n","      x = Reshape((output_len, self.depth))(x) \n","\n","      # loop over our number of layers. The number of unitis is decreased until we reach a number equal to the channels number (x2)\n","      for i in range(self.gen_layers):\n","        x = Conv1DTranspose(self.depth*2**i, self.kernel, padding=\"same\", dilation_rate=self.dil,\n","                            # kernel_regularizer='l1', bias_regularizer='l1',\n","                            )(x)\n","        x = ReLU()(x)\n","        # x = MaxPool1D(2)(x)\n","\n","        # x = BatchNormalization()(x)\n","        \n","        if self.dropout != None:\n","          x = Dropout(self.dropout)(x)\n","\n","      # apply a single CONV_TRANSPOSE layer used to recover the original depth of the signal\n","      x = Conv1DTranspose(self.channels*2, self.kernel, padding=\"same\", dilation_rate=self.dil)(x) ###########\n","\n","      outputs = custom_activation(x)\n","\n","      # build the generator model\n","      generator = Model(inputs, outputs, name=\"generator\")\n","\n","      return generator\n","\n","\n","  def discriminator(self):\n","\n","    input_len = self.snippet_len//2+1   \n","\n","    inputs = Input(shape=(input_len, 2*self.channels))\n","    x = inputs\n","\n","    # loop over our number of layers. At each step we increase the number of units\n","    for i in range(self.dis_layers):\n","      x = Conv1D(self.depth*2**i, self.kernel, padding=\"same\", dilation_rate=self.dil, \n","                          # kernel_regularizer='l1', bias_regularizer='l1',\n","                          )(x)\n","      x = PReLU()(x)\n","\n","      # x = BatchNormalization()(x)\n","      \n","      if self.dropout != None:\n","        x = Dropout(self.dropout)(x)\n","\n","\n","    x = Flatten()(x)\n","\n","    outputs = Dense(1,activation='sigmoid')(x)\n","\n","    discriminator = Model(inputs, outputs, name=\"discriminator\")\n","\n","    return discriminator\n","\n","\n","  # we compile the D. We also need it uncompiled in order to compile it in the adversarial model (with the G)\n","  def discriminator_compiled(self, D):\n","    opt = Adam(lr=self.INIT_LR, decay=self.DECAY)\n","    D.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    return D\n","\n","  # adversarial model. G and D together but only G is trainable\n","  def adversarial_model(self, G, D):\n","\n","    opt = Adam(lr=self.INIT_LR, decay=self.DECAY)\n","    D.trainable = False\n","    AM = Sequential()\n","    AM.add(G)\n","    AM.add(D)\n","    AM.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    return AM\n","\n","\n","  # We generate fake signals. The output of the G is transformed on the time domain\n","  def generate_fake_signals(self, n_samples):\n","\n","    noise = np.random.uniform(0, 1, (n_samples, self.latentDim))\n","    generated = self.G.predict(noise)\n","\n","    signal = fourier_2_signal(generated, self.snippet_len)\n","    return signal\n","\n","  # train the GAN\n","  # We can implement noisy_labels and smoothen labels in a non-noisy manner. We can also save plots \n","  #of examples of generated signals in savepath directory\n","  def train(self, train_set, epochs, batch_size, noisy_labels=False, smoothen_labels=0, savepath=None):\n","\n","    batches = train_set.shape[0]//batch_size\n","    progress_bar = Progbar(target=batches)\n","\n","    if smoothen_labels != 0:\n","      l = tf.keras.losses.BinaryCrossentropy(label_smoothing=smoothen_labels)\n","      opt = Adam(lr=self.INIT_LR, decay=self.DECAY)\n","      self.Adversarial.compile(loss=l, optimizer=opt, metrics=['accuracy'])\n","      self.D.compile(loss=l, optimizer=opt, metrics=['accuracy'])\n","\n","    for epoch in range(epochs):\n","      \n","      train_set = shuffle(train_set)\n","\n","      # TRAIN\n","      for idx in range(batches):\n","\n","        # take batch_size number of real signals\n","        signals_real = train_set[idx*batch_size : (idx+1)*batch_size, :, :]\n","        \n","        # generate batch_size number of fake signals\n","        noise = np.random.uniform(0, 1, size=[batch_size, self.latentDim])\n","        signals_fake = self.G.predict(noise)\n","\n","        x = np.concatenate((signals_real, signals_fake))\n","\n","        if noisy_labels:\n","          y = np.random.uniform(0.7, 1.0, (2*batch_size, 1))\n","          y[batch_size:, :] = np.random.uniform(0, 0.3, (batch_size, 1))\n","        else:  \n","          y = np.ones([2*batch_size, 1])\n","          y[batch_size:, :] = 0\n","\n","        # train discriminator\n","        d_loss = self.D.train_on_batch(x, y)\n","\n","        # train adversarial model\n","        if noisy_labels:\n","          y = np.random.uniform(0.7, 1.0, (batch_size, 1))\n","        else:\n","          y = np.ones([batch_size, 1])\n","\n","\n","        noise = np.random.uniform(0, 1, size=[batch_size, self.latentDim])\n","        a_loss = self.Adversarial.train_on_batch(noise, y)\n","\n","        progress_bar.update(idx)\n","\n","\n","      # every 10 epochs save an example\n","      if epoch % 10 == 0 and savepath != None:\n","        fake = self.generate_fake_signals(4)\n","        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15,15))\n","        ax1.plot(np.arange(fake.shape[1]), fake[0])\n","        ax2.plot(np.arange(fake.shape[1]), fake[1])\n","        ax3.plot(np.arange(fake.shape[1]), fake[2])\n","        ax4.plot(np.arange(fake.shape[1]), fake[3])\n","        plt.savefig(savepath + str(epoch) + '.png')\n","        plt.close()\n","\n","      log_mesg = ' EPOCH %d: [D loss: %f, acc: %f]   [A loss: %f, acc: %f]' % (epoch, d_loss[0], d_loss[1], a_loss[0], a_loss[1])\n","      print(log_mesg)\n","  \n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkjOAqfvx77s"},"source":["*f-anoGAN*"]},{"cell_type":"code","metadata":{"id":"dVHWiwWYOpFZ"},"source":["'''\n","Implementation of the f-anoGAN. After intializing it, we should call build_encoder to build the encoder and then train it.\n","gan: GAN in which the f-anoGAN will be based. It can be a limeGAN too.\n","freq: True if we use a limeGAN\n","'''\n","class FANOGAN:\n","  def __init__(self, gan, freq=False):\n","\n","    self.gan = gan\n","    self.D = gan.D\n","    self.G = gan.G\n","\n","    self.freq = freq # whether we use the LimeGAN\n","\n","    self.kappa = None\n","    self.DF = None\n","\n","    self.encoder = None\n","    self.autoencoder = None\n","\n","\n","  def save(self, filename):\n","\n","    d = {\n","    'kernel' : self.gan.kernel,\n","    'gen_layers' : self.gan.gen_layers, \n","    'dis_layers' : self.gan.dis_layers, \n","    'latentDim' : self.gan.latentDim,\n","    'depth'  : self.gan.depth,\n","    'dil' :self.gan.dil,\n","    'snippet_len' : self.gan.snippet_len,\n","    'channels' : self.gan.channels,\n","    'dropout' : self.gan.dropout,\n","    'G_json' : self.gan.G.to_json(),\n","    'G_weights' : self.gan.G.get_weights(),\n","    'D_json' : self.gan.D_uncompiled.to_json(),\n","    'D_weights' : self.gan.D_uncompiled.get_weights(),\n","    'kappa' : self.kappa,\n","    'encoder_weights' : self.encoder.get_weights(),\n","    'encoder_json' : self.encoder.to_json(),\n","    'freq' : self.freq\n","    }\n","    \n","    dump(d, open(filename + '.model', 'wb'))\n","    \n","\n","\n","  @staticmethod\n","  def load(filename):\n","\n","    d = load(open(filename + '.model', 'rb'))\n","\n","    if d['freq']:\n","      gan = limeGAN(d['kernel'], d['gen_layers'], d['dis_layers'], d['latentDim'], \n","              d['depth'], d['dil'], d['snippet_len'],  d['channels'], d['dropout'])\n","    else:\n","      gan = GAN(d['kernel'], d['gen_layers'], d['dis_layers'], d['latentDim'], \n","              d['depth'], d['dil'], d['snippet_len'],  d['channels'], d['dropout'])\n","    \n","\n","    G = model_from_json(d['G_json'])\n","    G.set_weights(d['G_weights'])\n","    gan.G = G\n","\n","    D_uncompiled = model_from_json(d['D_json'])\n","    D_uncompiled.set_weights(d['D_weights'])\n","    gan.D_uncompiled = D_uncompiled\n","\n","    gan.D = gan.discriminator_compiled(D_uncompiled)\n","    gan.Adversarial = gan.adversarial_model(G, D_uncompiled)\n","\n","    fanogan = FANOGAN(gan, freq=d['freq'])\n","\n","    fanogan.kappa = d['kappa']\n","\n","    encoder = model_from_json(d['encoder_json'])\n","    encoder.set_weights(d['encoder_weights'])\n","    fanogan.encoder = encoder\n","\n","    fanogan.build_autoencoder()\n","    fanogan.discriminator_features()\n","\n","    return fanogan\n","\n","\n","  # We build the encoder of the f-anoGAN. We define the kernel size and how many layers  \n","  def build_encoder(self, kernel, layers, dil=1, dropout=None):\n","\n","    latentDim = self.gan.latentDim\n","    snippet_len = self.gan.snippet_len\n","    channels = self.gan.channels\n","\n","    if self.freq:\n","      snippet_len = snippet_len//2 + 1\n","      channels = 2*channels\n","\n","    # initialize the input shape to be \"channels last\" along with the channels dimension itself\n","    inputShape = (snippet_len, channels)\n","\n","    # define the input to the encoder\n","    inputs = Input(shape=inputShape)\n","\n","    x = inputs\n","    # loop over the number of layers. At each layer we half the depth\n","    for i in range(layers):\n","      x = Conv1D(self.gan.depth//2**i, kernel, padding=\"same\", dilation_rate=dil,\n","                #  kernel_regularizer='l1', bias_regularizer='l1',\n","                 )(x)\n","      x = ReLU()(x)\n","\n","      if dropout != None:\n","        x = Dropout(dropout)(x)\n","\n","    x = Flatten()(x)\n","    latent = Dense(latentDim, activation='sigmoid')(x)\n","\n","    encoder = Model(inputs, latent)\n","\n","    self.encoder = encoder\n","    self.build_autoencoder()\n","\n","\n","  # method is izi or ziz\n","  def build_autoencoder(self):\n","\n","    encoder = self.encoder\n","    G = self.G\n","\n","    G.trainable = False\n","\n","    snippet_len = self.gan.snippet_len\n","    channels = self.gan.channels\n","\n","    if self.freq:\n","      snippet_len = snippet_len//2 + 1\n","      channels = 2*channels\n","\n","    inputs = Input(shape=(snippet_len, channels))\n","    x = self.encoder(inputs)\n","    outputs = G(x)\n","    self.autoencoder = Model(inputs, outputs)\n","\n","\n","  def anomaly_score(self, data, kappa=None):\n","\n","    # reconstruction error\n","    predicted = self.autoencoder.predict(data)\n","    AR = np.mean((data-predicted)**2, axis=(1,2))\n","\n","    if kappa is not None:\n","      # discriminator features\n","      f = self.DF\n","      f_x = f.predict(data)\n","      predicted_f_x = f.predict(predicted)\n","      AD = np.mean((f_x - predicted_f_x)**2)\n","\n","      return AR + kappa*AD\n","    \n","    else:\n","      return AR\n","    \n","  #  snippet_len should be integer multiple of segment_len\n","  def anomaly_per_segment(self, data, segment_len=125):\n","\n","    if self.freq:\n","      original = fourier_2_signal(data, self.gan.snippet_len)\n","      reconstructed = fourier_2_signal(self.autoencoder.predict(data), self.gan.snippet_len)\n","    else:\n","      original = data\n","      reconstructed = self.autoencoder.predict(data)\n","\n","    original = original.reshape(-1, segment_len, self.gan.channels)\n","    reconstructed = reconstructed.reshape(-1, segment_len, self.gan.channels)\n","\n","    errors = np.mean((original-reconstructed)**2, axis=(1,2))\n","\n","    return errors\n","\n","\n","\n","  \n","  def discriminator_features(self):\n","    self.DF = Model(inputs=self.D.layers[0].input, outputs=self.D.layers[-3].output)\n","\n","\n","  def discriminator_guided_loss(self, x, y):\n","\n","      # AR = K.mean((x-y)**2)\n","      AR = K.mean(K.abs((x-y)))\n","\n","      f_x = self.DF(x)\n","      f_y = self.DF(y)\n","\n","      # AD = K.mean((f_x-f_y)**2)\n","      AD = K.mean(K.abs((f_x-f_y)))\n","\n","      return AR + self.kappa*AD\n","\n","\n","\n","  \n","  def train_autoencoder_izi(self, d_train, d_val, EPOCHS, b_size, kappa=None, INIT_LR=1e-4):\n","\n","    DECAY = INIT_LR/EPOCHS\n","\n","    opt = Adam(lr=INIT_LR, decay=DECAY)\n","    \n","    if kappa is None:\n","      self.autoencoder.compile(loss='mae', optimizer=opt)\n","\n","      self.autoencoder.fit(x=d_train, y=d_train, batch_size=b_size, epochs=EPOCHS, validation_data=(d_val, d_val),\n","                      # steps_per_epoch=steps,  callbacks=callbacks_list, verbose=2\n","                      ) \n","    \n","    else:\n","\n","      self.kappa = kappa\n","      self.discriminator_features()\n","\n","      self.autoencoder.compile(loss=self.discriminator_guided_loss, optimizer=opt)\n","\n","      self.autoencoder.fit(x=d_train, y=d_train, batch_size=b_size, epochs=EPOCHS, validation_data=(d_val, d_val),\n","                      # steps_per_epoch=steps,  callbacks=callbacks_list, verbose=2\n","                      ) \n","      \n","  \n","  def train_autoencoder_ziz(self, train_samples, val_samples, EPOCHS, b_size=128, INIT_LR=1e-4):\n","\n","    DECAY = INIT_LR/EPOCHS\n","    opt = Adam(lr=INIT_LR, decay=DECAY)\n","\n","    # create ziz model\n","\n","    encoder = self.encoder\n","    G = self.G\n","    G.trainable = False\n","\n","    inputs = Input(shape=(self.gan.latentDim))\n","    x = G(inputs)\n","    outputs = encoder(x)\n","    ziz_model = Model(inputs, outputs)\n","\n","    ziz_model.compile(loss='mse', optimizer=opt)\n","\n","    d_train = np.random.uniform(0, 1, (train_samples, self.gan.latentDim))\n","    d_val = np.random.uniform(0, 1, (val_samples, self.gan.latentDim))\n","\n","    ziz_model.fit(x=d_train, y=d_train, batch_size=b_size, epochs=EPOCHS, validation_data=(d_val, d_val)) \n","\n","\n","    # build autoencoder\n","\n","    snippet_len = self.gan.snippet_len\n","    channels = self.gan.channels\n","\n","    if self.freq:\n","      snippet_len = snippet_len//2 + 1\n","      channels = 2*channels\n","\n","    inputs = Input(shape=(snippet_len, channels))\n","    x = ziz_model.layers[-1](inputs)\n","    outputs = self.G(x)\n","    self.autoencoder = Model(inputs, outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t_Ybb3Zax-gX"},"source":["*anoGAN*"]},{"cell_type":"code","metadata":{"id":"7ErGnWAp8Sn6"},"source":["# anoGAN loss function. We will have two outputs, the output of G and the discriminator features. \n","# Then we use this loss function with specific weights\n","def sum_of_residual(y_true, y_pred):\n","    return tf.reduce_sum(tf.abs(y_true - y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvgAMCgb76tP"},"source":["'''\n","anoGAN implementation\n","gan: GAN in which the f-anoGAN will be based. It can be a limeGAN too.\n","freq: True if we use a limeGAN\n","gamma: How many epochs we will use in each inverse mapping iteration\n","We don't need to save it because there is no learning. Saving the GAN is enough\n","'''\n","class ANOGAN:\n","  def __init__(self, gan, kappa=0.1, gamma=500, freq=True):\n","    self.gan = gan\n","    self.G = gan.G\n","    self.D = gan.D\n","    self.gamma = gamma\n","    self.kappa = kappa\n","    self.f = Model(inputs=self.D.layers[0].input, outputs=self.D.layers[-2].output)\n","    self.freq = freq\n","\n","    self.snippet_len = self.gan.snippet_len\n","    self.channels = self.gan.channels\n","    self.latentDim = self.gan.latentDim\n","\n","    if freq:\n","      self.snippet_len = self.snippet_len //2 + 1\n","      self.channels = self.channels * 2\n","\n","\n","  # anomaly score using a singe-layer NN for each sample, using the loss function defined in the anoGAN paper\n","  # It works in finding the correct inverse mapping (tested) and is actually quite fast, since it is using optimized code,\n","  # in comparison with my Python loop\n","  # Courtesy of https://github.com/yjucho1/anoGAN\n","  def build_anomaly_detector(self):\n","\n","      G = self.G\n","      G.trainable = False\n","\n","      intermidiate_model = self.f\n","      intermidiate_model.trainable = False\n","      \n","      aInput = Input(shape=(self.latentDim,))\n","\n","      # project to latent space\n","      latent = Dense(self.gan.latentDim, 'sigmoid')(aInput)\n","\n","      # pass through generator again\n","      G_out = G(latent)\n","\n","      # discriminator features\n","      D_out= intermidiate_model(G_out)    \n","      model = Model(inputs=aInput, outputs=[G_out, D_out])\n","\n","      model.compile(loss=sum_of_residual, loss_weights= [1-self.kappa, self.kappa], optimizer='adam')\n","\n","      return model\n","\n","\n","  def compute_anomaly_score(self, x):    \n","\n","    # initial approximation of z\n","    z = np.random.uniform(0, 1, size=(1, self.gan.latentDim))\n","\n","    intermidiate_model = self.f\n","\n","    x = np.expand_dims(x, axis=0)\n","    \n","    d_x = intermidiate_model.predict(x)\n","\n","    d_x = np.expand_dims(d_x, axis=0)\n","\n","    anomaly_detector = self.build_anomaly_detector()\n","\n","    loss = anomaly_detector.fit(z, [x, d_x], epochs=self.gamma, verbose=0)\n","    similar_data, _ = anomaly_detector.predict(z)\n","    return loss.history['loss'][-1], similar_data\n","\n","\n","  #########################################################################\n","   # Inverse mapping as explained in the anoGAN paper (IT DOES NOT WORK)\n","\n","  # def inverse_mapping(self, x, a=1e-5):\n","\n","  #   x = np.expand_dims(x, 0)\n","\n","  #   z = np.random.uniform(0, 1, (1, self.gan.latentDim))\n","\n","  #   for _ in range(1000):\n","\n","  #     # calculate gradients of loss with respect to z\n","  #     z_tensor = tf.convert_to_tensor(z, dtype=tf.float32)\n","  #     with tf.GradientTape(watch_accessed_variables=False) as t:\n","  #         t.watch(z_tensor)\n","\n","  #         output = (1-self.kappa) * tf.math.reduce_sum(tf.math.abs(x - self.G(z_tensor))) + \\\n","  #         self.kappa * tf.math.reduce_sum(tf.math.abs(self.f(x) - self.f(self.G(z_tensor)))) # \n","\n","  #     grad_loss = t.gradient(output, z_tensor)\n","\n","  #     z = z - a * grad_loss\n","    \n","  #   loss =  (1-self.kappa) * tf.math.reduce_sum(tf.math.abs(x - self.G(z))) + \\\n","  #         self.kappa * tf.math.reduce_sum(tf.math.abs(self.f(x) - self.f(self.G(z))))\\\n","\n","  #   return loss, z\n","\n","\n"," #########################################################################     \n","\n","\n","  #  snippet_len should be integer multiple of segment_len\n","  def anomaly_per_segment(self, data, segment_len=125):\n","\n","    if self.freq:\n","      original = fourier_2_signal(data, self.gan.snippet_len)\n","\n","      reconstructed_fourier = np.zeros(data.shape)\n","      for i in range(data.shape[0]):\n","        reconstructed_fourier[i] =  self.compute_anomaly_score(data[i])[1]\n","\n","      reconstructed = fourier_2_signal(reconstructed_fourier, self.gan.snippet_len)\n","\n","    else:\n","      original = data\n","\n","      reconstructed = np.zeros(data.shape)\n","      for i in range(data.shape[0]):\n","        reconstructed[i] =  self.compute_anomaly_score(data[i])[1]\n","\n","\n","    original = original.reshape(-1, segment_len, self.gan.channels)\n","    reconstructed = reconstructed.reshape(-1, segment_len, self.gan.channels)\n","\n","    errors = np.mean((original-reconstructed)**2, axis=(1,2))\n","\n","    return errors\n","\n","  def anomaly_scores(self, data):\n","\n","    scores = np.zeros(data.shape[0])\n","\n","    for i in range(data.shape[0]):\n","      scores[i] =  self.compute_anomaly_score(data[i])[0] #  self.inverse_mapping(x)[0] # \n","\n","    return scores\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1e_SYtpdx1Pl"},"source":["*WGAN*"]},{"cell_type":"code","metadata":{"id":"yL1BXEizdmnR"},"source":["\t# clip model weights to a given hypercube\n","class ClipConstraint(Constraint):\n","\t# set clip value when initialized\n","  def __init__(self, clip_value=0.01):\n","    self.clip_value = clip_value\n"," \n","\t# clip model weights to hypercube\n","\tdef __call__(self, weights):\n","\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n"," \n","\t# get the config\n","\tdef get_config(self):\n","\t\treturn {'clip_value': self.clip_value}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNZrtFtKePdu"},"source":["  # implementation of wasserstein loss\n","  def wasserstein_loss(y_true, y_pred):\n","    return K.mean(y_true * y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ImEwUv-yiv2"},"source":["class WGAN:\n","  def __init__(self, kernel, gen_layers, dis_layers, latentDim, depth, clip=0.01, dil=1, snippet_len=125,  channels=4, dropout=None):\n","\n","    self.kernel = kernel\n","    self.gen_layers = gen_layers\n","    self.dis_layers = dis_layers\n","    self.latentDim = latentDim\n","    self.depth = depth\n","    self.dil = dil\n","    self.snippet_len = snippet_len\n","    self.channels = channels\n","    self.dropout = dropout\n","\n","    # define the constraint\n","    self.clip = clip\n","    self.const = ClipConstraint(clip)\n","\n","    self.G = self.generator()\n","    self.D_uncompiled = self.discriminator()\n","\n","    self.D = self.discriminator_compiled(self.D_uncompiled)\n","    self.Adversarial = self.adversarial_model(self.G, self.D_uncompiled)\n","\n","\n","     \n","  def save(self, filename):\n","    d = {\n","        'kernel' : self.kernel,\n","        'gen_layers' : self.gen_layers, \n","        'dis_layers' : self.dis_layers, \n","        'latentDim' : self.latentDim,\n","        'depth'  : self.depth,\n","         'clip' : self.clip,\n","        'dil' :self.dil,\n","        'snippet_len' : self.snippet_len,\n","        'channels' : self.channels,\n","        'dropout' : self.dropout,\n","         'G_json' : self.G.to_json(),\n","         'G_weights' : self.G.get_weights(),\n","          'D_json' : self.D_uncompiled.to_json(),\n","         'D_weights' : self.D_uncompiled.get_weights()\n","         }\n","\n","    dump(d, open(filename + '.model', 'wb'))\n","\n","  \n","  @staticmethod\n","  def load(filename):\n","    d = load(open(filename + '.model', 'rb'))\n","\n","    gan = WGAN(d['kernel'], d['gen_layers'], d['dis_layers'], d['latentDim'], \n","              d['depth'], d['clip'], d['dil'], d['snippet_len'],  d['channels'], d['dropout'])\n","    \n","\n","    G = model_from_json(d['G_json'])\n","    G.set_weights(d['G_weights'])\n","    gan.G = G\n","\n","    D_uncompiled = model_from_json(d['D_json'], {'ClipConstraint' : ClipConstraint, 'clip_value' : d['clip']})\n","    D_uncompiled.set_weights(d['D_weights'])\n","    gan.D_uncompiled = D_uncompiled\n","\n","    gan.D = gan.discriminator_compiled(D_uncompiled)\n","    gan.Adversarial = gan.adversarial_model(G, D_uncompiled)\n","\n","    return gan\n","\n","\n","  def generator(self):\n","\n","      inputs = Input(shape=(self.latentDim,))\n","\n","      x = Dense(self.snippet_len * self.depth)(inputs)\n","\n","      x = Reshape((self.snippet_len, self.depth))(x)\n","\n","      # double the number of units per loop\n","      for i in range(self.gen_layers):\n","        x = Conv1DTranspose(self.depth*2**i, self.kernel, padding=\"same\", dilation_rate=self.dil, \n","                            # kernel_regularizer='l1', bias_regularizer='l1',\n","                            )(x)\n","        x = ReLU()(x)\n","\n","        x = BatchNormalization()(x)\n","        \n","        if self.dropout != None:\n","          x = Dropout(self.dropout)(x)\n","\n","      # apply a single CONV_TRANSPOSE layer used to recover the original depth of the signal\n","      x = Conv1DTranspose(self.channels, self.kernel, padding=\"same\", dilation_rate=self.dil)(x)\n","      outputs = x\n","      \n","      # build the generator model\n","      generator = Model(inputs, outputs, name=\"generator\")\n","\n","      return generator\n","\n","\n","  def discriminator(self):\n","\n","    inputs = Input(shape=(self.snippet_len, self.channels))\n","    x = inputs\n","\n","    # loop over our number of filters again, but this time in reverse order\n","    for i in range(self.dis_layers):\n","      x = Conv1D(self.depth*2**i, self.kernel, padding=\"same\", dilation_rate=self.dil, \n","                          # kernel_regularizer='l1', bias_regularizer='l1',\n","                          kernel_constraint=self.const,\n","                          )(x)\n","      x = PReLU()(x)\n","\n","      # x = BatchNormalization()(x)\n","      \n","      if self.dropout != None:\n","        x = Dropout(self.dropout)(x)\n","\n","\n","    x = Flatten()(x)\n","\n","    outputs = Dense(1, activation='linear')(x)\n","\n","    discriminator = Model(inputs, outputs, name=\"discriminator\")\n","\n","    return discriminator\n","\n","\n","  \n","  def discriminator_compiled(self, D, INIT_LR=0.00005):\n","    opt = RMSprop(lr=INIT_LR)\n","    D.compile(loss=wasserstein_loss, optimizer=opt, metrics=['binary_accuracy'])\n","    return D\n","\n","\n","  def adversarial_model(self, G, D, INIT_LR=0.00005):\n","\n","    opt = RMSprop(lr=INIT_LR)\n","    D.trainable = False\n","    AM = Sequential()\n","    AM.add(G)\n","    AM.add(D)\n","    AM.compile(loss=wasserstein_loss, optimizer=opt, metrics=['binary_accuracy'])\n","    return AM\n","\n","\n","\n","  ### generate images\n","  def generate_fake_signals(self, n_samples):\n","    noise = np.random.uniform(0, 1, (n_samples, self.latentDim))\n","    generated_signals = self.G.predict(noise)\n","    return generated_signals\n","\n","\n","  def train(self, train_set, epochs=1000, batch_size=256, n_critic=5, savepath=None):\n","\n","    batches = train_set.shape[0]//batch_size\n","    progress_bar = Progbar(target=batches)\n","\n","    for epoch in range(epochs):\n","      \n","      train_set = shuffle(train_set)\n","\n","      # TRAIN\n","      for idx in range(batches):\n","\n","        # take batch_size number of real signals\n","        signals_real = train_set[idx*batch_size : (idx+1)*batch_size, :, :]\n","\n","        for  j in range(n_critic):\n","          # mini_batch_size = batch_size//n_critic\n","          # mini_signals_real = signals_real[j*mini_batch_size : (j+1)*mini_batch_size]\n","          # generate batch_size number of fake signals\n","          noise = np.random.normal(0, 1, size=[batch_size, self.latentDim])\n","          signals_fake = self.G.predict(noise)\n","\n","          x = np.concatenate((signals_real, signals_fake))\n","\n","          y = np.ones([2*batch_size, 1])\n","          y[:batch_size, :] = -1\n","\n","          # train discriminator\n","          d_loss = self.D.train_on_batch(x, y)\n","\n","        # train adversarial model\n","        y = np.ones([batch_size, 1]) * (-1)\n","\n","        noise = np.random.normal(0, 1, size=[batch_size, self.latentDim])\n","        a_loss = self.Adversarial.train_on_batch(noise, y)\n","\n","        progress_bar.update(idx)\n","\n","      # every 10 epochs save an example\n","      if epoch % 10 == 0 and savepath != None:\n","        fake = self.generate_fake_signals(4)\n","        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15,15))\n","        ax1.plot(np.arange(fake.shape[1]), fake[0,:,0])\n","        ax2.plot(np.arange(fake.shape[1]), fake[1,:,0])\n","        ax3.plot(np.arange(fake.shape[1]), fake[2,:,0])\n","        ax4.plot(np.arange(fake.shape[1]), fake[3,:,0])\n","        plt.savefig(savepath + str(epoch) + '.png')\n","        plt.close()\n","\n","      log_mesg = ' EPOCH %d: [D loss: %f, acc: %f]   [A loss: %f, acc: %f]' % (epoch, d_loss[0], d_loss[1], a_loss[0], a_loss[1])\n","      print(log_mesg)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D9Tcy5BB7yeW"},"source":["*Traditional GAN*"]},{"cell_type":"code","metadata":{"id":"RfPCAUhpc_-p"},"source":["class GAN:\n","  def __init__(self, kernel, gen_layers, dis_layers, latentDim, depth, dil=1, \n","               snippet_len=125,  channels=4, dropout=None, INIT_LR=1e-5, DECAY=6e-8):\n","\n","    self.kernel = kernel\n","    self.gen_layers = gen_layers\n","    self.dis_layers = dis_layers\n","    self.latentDim = latentDim\n","    self.depth = depth\n","    self.dil = dil\n","    self.snippet_len = snippet_len\n","    self.channels = channels\n","    self.dropout = dropout\n","\n","\n","    self.INIT_LR = INIT_LR\n","    self.DECAY = DECAY\n","\n","    self.G = self.generator()\n","    self.D_uncompiled = self.discriminator()\n","\n","    self.D = self.discriminator_compiled(self.D_uncompiled)\n","    self.Adversarial = self.adversarial_model(self.G, self.D_uncompiled)\n","\n","\n","  def generator(self):\n","\n","      inputs = Input(shape=(self.latentDim,))\n","\n","      x = Dense(self.snippet_len * self.depth)(inputs)\n","\n","      x = Reshape((self.snippet_len, self.depth))(x)\n","\n","      # loop over our number of filters again, but this time in reverse order\n","      for i in range(self.gen_layers):\n","        x = Conv1DTranspose(self.depth*2**i, self.kernel, padding=\"same\", dilation_rate=self.dil, #strides=2,\n","                            # kernel_regularizer='l1', bias_regularizer='l1',\n","                            )(x)\n","        x = ReLU()(x)\n","        # x = MaxPool1D(2)(x)\n","\n","        # x = BatchNormalization()(x)\n","        \n","        if self.dropout != None:\n","          x = Dropout(self.dropout)(x)\n","\n","      # apply a single CONV_TRANSPOSE layer used to recover the original depth of the signal\n","      x = Conv1DTranspose(self.channels, self.kernel, padding=\"same\", dilation_rate=self.dil)(x)\n","      # outputs = K.tanh(x)\n","      outputs = x\n","      \n","      # build the generator model\n","      generator = Model(inputs, outputs, name=\"generator\")\n","\n","      return generator\n","\n","\n","  def discriminator(self):\n","\n","    inputs = Input(shape=(self.snippet_len, self.channels))\n","    x = inputs\n","\n","    # loop over our number of filters again, but this time in reverse order\n","    for i in range(self.dis_layers):\n","      x = Conv1D(self.depth*2**i, self.kernel, padding=\"same\", dilation_rate=self.dil, \n","                          # kernel_regularizer='l1', bias_regularizer='l1',\n","                          )(x)\n","      x = PReLU()(x)\n","\n","      # x = BatchNormalization()(x)\n","      \n","      if self.dropout != None:\n","        x = Dropout(self.dropout)(x)\n","\n","\n","    x = Flatten()(x)\n","\n","    outputs = Dense(1,activation='sigmoid')(x)\n","\n","    discriminator = Model(inputs, outputs, name=\"discriminator\")\n","\n","    return discriminator\n","\n","\n","  \n","  def discriminator_compiled(self, D):\n","    opt = Adam(lr=self.INIT_LR, decay=self.DECAY)\n","    D.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    return D\n","\n","\n","  def adversarial_model(self, G, D):\n","\n","    opt = Adam(lr=self.INIT_LR, decay=self.DECAY)\n","    D.trainable = False\n","    AM = Sequential()\n","    AM.add(G)\n","    AM.add(D)\n","    AM.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    return AM\n","\n","\n","  def save(self, filename):\n","    d = {\n","        'kernel' : self.kernel,\n","        'gen_layers' : self.gen_layers, \n","        'dis_layers' : self.dis_layers, \n","        'latentDim' : self.latentDim,\n","        'depth'  : self.depth,\n","        'dil' :self.dil,\n","        'snippet_len' : self.snippet_len,\n","        'INIT_LR' : self.INIT_LR,\n","         'DECAY' : self.DECAY,\n","        'channels' : self.channels,\n","        'dropout' : self.dropout,\n","         'G_json' : self.G.to_json(),\n","         'G_weights' : self.G.get_weights(),\n","          'D_json' : self.D_uncompiled.to_json(),\n","         'D_weights' : self.D_uncompiled.get_weights()\n","         }\n","\n","    dump(d, open(filename + '.model', 'wb'))\n","\n","  \n","  @staticmethod\n","  def load(filename):\n","    d = load(open(filename + '.model', 'rb'))\n","\n","    gan = GAN(d['kernel'], d['gen_layers'], d['dis_layers'], d['latentDim'], \n","              d['depth'], d['dil'], d['snippet_len'],  d['channels'], d['dropout'], d['INIT_LR'], d['DECAY'])\n","    \n","\n","    G = model_from_json(d['G_json'])\n","    G.set_weights(d['G_weights'])\n","    gan.GAN = G\n","\n","    D_uncompiled = model_from_json(d['D_json'])\n","    D_uncompiled.set_weights(d['D_weights'])\n","    gan.D_uncompiled = D_uncompiled\n","\n","    gan.D = gan.discriminator_compiled(D_uncompiled)\n","    gan.Adversarial = gan.adversarial_model(G, D_uncompiled)\n","\n","    return gan\n","\n","\n","  ### generate images\n","  def generate_fake_signals(self, n_samples):\n","    noise = np.random.uniform(0, 1, (n_samples, self.latentDim))\n","    generated_signals = self.G.predict(noise)\n","    return generated_signals\n","\n","\n","\n","  def train(self, train_set, epochs, batch_size, noisy_labels=False, smoothen_labels=0, savepath=None):\n","\n","    batches = train_set.shape[0]//batch_size\n","    progress_bar = Progbar(target=batches)\n","\n","    if smoothen_labels != 0:\n","      l = tf.keras.losses.BinaryCrossentropy(label_smoothing=smoothen_labels)\n","      opt = Adam(lr=self.INIT_LR, decay=self.DECAY)\n","      self.Adversarial.compile(loss=l, optimizer=opt, metrics=['accuracy'])\n","      self.D.compile(loss=l, optimizer=opt, metrics=['accuracy'])\n","\n","\n","    for epoch in range(epochs):\n","      \n","      train_set = shuffle(train_set)\n","\n","      # TRAIN\n","      for idx in range(batches):\n","\n","        # take batch_size number of real signals\n","        signals_real = train_set[idx*batch_size : (idx+1)*batch_size, :, :]\n","        \n","        # generate batch_size number of fake signals\n","        noise = np.random.uniform(0, 1, size=[batch_size, self.latentDim])\n","        signals_fake = self.G.predict(noise)\n","\n","        x = np.concatenate((signals_real, signals_fake))\n","\n","        if noisy_labels:\n","          y = np.random.uniform(0.7, 1.0, (2*batch_size, 1))\n","          y[batch_size:, :] = np.random.uniform(0, 0.3, (batch_size, 1))\n","        else:  \n","          y = np.ones([2*batch_size, 1])\n","          y[batch_size:, :] = 0\n","\n","        # train discriminator\n","        d_loss = self.D.train_on_batch(x, y)\n","\n","        # train adversarial model\n","        if noisy_labels:\n","          y = np.random.uniform(0.7, 1.0, (batch_size, 1))\n","        else:\n","          y = np.ones([batch_size, 1])\n","\n","        noise = np.random.uniform(0, 1, size=[batch_size, self.latentDim])\n","        a_loss = self.Adversarial.train_on_batch(noise, y)\n","\n","        progress_bar.update(idx)\n","\n","\n","      log_mesg = ' EPOCH %d: [D loss: %f, acc: %f]   [A loss: %f, acc: %f]' % (epoch, d_loss[0], d_loss[1], a_loss[0], a_loss[1])\n","      print(log_mesg)\n","  \n","      # every 10 epochs save an example\n","      if epoch % 10 == 0  and savepath != None:\n","        fake = self.generate_fake_signals(4)\n","        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15,15))\n","        ax1.plot(np.arange(fake.shape[1]), fake[0])\n","        ax2.plot(np.arange(fake.shape[1]), fake[1])\n","        ax3.plot(np.arange(fake.shape[1]), fake[2])\n","        ax4.plot(np.arange(fake.shape[1]), fake[3])\n","        plt.savefig(savepath + str(epoch) + '.png')\n","        plt.close()\n","\n","\n"],"execution_count":null,"outputs":[]}]}